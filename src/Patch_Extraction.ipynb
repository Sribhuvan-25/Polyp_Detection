{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import cv2\n",
    "import numpy as np\n",
    "from read_roi import read_roi_file\n",
    "import matplotlib.pyplot as plt\n",
    "import logging\n",
    "\n",
    "# Set up basic configuration for logging\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "\n",
    "def get_roi_coordinates(roi_file_path):\n",
    "    roi = read_roi_file(roi_file_path)\n",
    "    for box_info in roi.values():\n",
    "        if box_info['type'] == 'rectangle':\n",
    "            center_x = box_info['left'] + box_info['width'] // 2\n",
    "            center_y = box_info['top'] + box_info['height'] // 2\n",
    "            return center_x, center_y\n",
    "    return None\n",
    "\n",
    "def visualize_and_save(image, output_path, title):\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.imshow(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))\n",
    "    plt.title(title)\n",
    "    plt.axis('off')\n",
    "    plt.savefig(output_path)\n",
    "    plt.close()\n",
    "\n",
    "def extract_patches(image, center_x, center_y, ideal_patch_size, output_folder, base_filename):\n",
    "    visualization_image = image.copy()\n",
    "    sp_start_x = max(center_x - ideal_patch_size[1] // 2, 0)\n",
    "    sp_start_y = max(center_y - ideal_patch_size[0] // 2, 0)\n",
    "    sp_end_x = min(sp_start_x + ideal_patch_size[1], image.shape[1])\n",
    "    sp_end_y = min(sp_start_y + ideal_patch_size[0], image.shape[0])\n",
    "\n",
    "    patch = image[sp_start_y:sp_end_y, sp_start_x:sp_end_x]\n",
    "    patch_name = f\"{base_filename}_patch.png\"\n",
    "    cv2.imwrite(os.path.join(output_folder, patch_name), patch)\n",
    "    cv2.rectangle(visualization_image, (sp_start_x, sp_start_y), (sp_end_x, sp_end_y), (0, 255, 0), 3)\n",
    "\n",
    "    return visualization_image\n",
    "\n",
    "def extract_normal_patches(image, ideal_patch_size, output_folder, base_filename):\n",
    "    h, w, _ = image.shape\n",
    "    visualization_image = image.copy()\n",
    "    attempts = 0\n",
    "    centers = []\n",
    "\n",
    "    while len(centers) < 2 and attempts < 100:\n",
    "        center_x = random.randint(w // 4, 3 * w // 4)\n",
    "        center_y = random.randint(h // 4, 3 * h // 4)\n",
    "\n",
    "        sp_start_x = max(center_x - ideal_patch_size[1] // 2, 0)\n",
    "        sp_start_y = max(center_y - ideal_patch_size[0] // 2, 0)\n",
    "        sp_end_x = min(sp_start_x + ideal_patch_size[1], w)\n",
    "        sp_end_y = min(sp_start_y + ideal_patch_size[0], h)\n",
    "\n",
    "        if not any([sp_start_x < ex + ew and sp_end_x > ex and sp_start_y < ey + eh and sp_end_y > ey for ex, ey, ew, eh in centers]):\n",
    "            centers.append((sp_start_x, sp_start_y, sp_end_x - sp_start_x, sp_end_y - sp_start_y))\n",
    "            patch = image[sp_start_y:sp_end_y, sp_start_x:sp_end_x]\n",
    "            patch_name = f\"{base_filename}_normal_patch_{len(centers)}.png\"\n",
    "            cv2.imwrite(os.path.join(output_folder, patch_name), patch)\n",
    "            cv2.rectangle(visualization_image, (sp_start_x, sp_start_y), (sp_end_x, sp_end_y), (0, 255, 0), 3)\n",
    "        attempts += 1\n",
    "\n",
    "    return visualization_image\n",
    "\n",
    "def process_image(folder, output_folder, visualization_folder, ideal_patch_size=(275, 300), is_abnormal=True):\n",
    "    os.makedirs(output_folder, exist_ok=True)\n",
    "    os.makedirs(visualization_folder, exist_ok=True)\n",
    "\n",
    "    for filename in os.listdir(folder):\n",
    "        if filename.endswith(('.jpg', '.jpeg', '.png')):\n",
    "            image_path = os.path.join(folder, filename)\n",
    "            image = cv2.imread(image_path)\n",
    "            if image is None:\n",
    "                logging.warning(f\"Failed to read image: {image_path}\")\n",
    "                continue\n",
    "\n",
    "            base_filename = os.path.splitext(filename)[0]\n",
    "            if is_abnormal:\n",
    "                roi_path = os.path.splitext(image_path)[0] + \".roi\"\n",
    "                if os.path.exists(roi_path):\n",
    "                    center_x, center_y = get_roi_coordinates(roi_path)\n",
    "                    visualization_image = extract_patches(image, center_x, center_y, ideal_patch_size, output_folder, base_filename)\n",
    "            else:\n",
    "                visualization_image = extract_normal_patches(image, ideal_patch_size, output_folder, base_filename)\n",
    "\n",
    "            visualization_path = os.path.join(visualization_folder, f\"{base_filename}_visualization.png\")\n",
    "            visualize_and_save(visualization_image, visualization_path, \"Extracted Patches\")\n",
    "\n",
    "def process_dirs(data_dir, output_dir, visualization_dir, ideal_patch_size=(275, 300)):\n",
    "    for class_type in ['normal', 'abnormal']:\n",
    "        input_dir = os.path.join(data_dir, class_type)\n",
    "        output_sub_dir = os.path.join(output_dir, class_type)\n",
    "        visualization_sub_dir = os.path.join(visualization_dir, class_type)\n",
    "        process_image(input_dir, output_sub_dir, visualization_sub_dir, ideal_patch_size, is_abnormal=(class_type == 'abnormal'))\n",
    "\n",
    "# Example usage\n",
    "data_dir = 'Data'\n",
    "output_dir = 'output_patches_new'\n",
    "visualization_dir = 'visualizations_patches_new'\n",
    "\n",
    "process_dirs(data_dir, output_dir, visualization_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import cv2\n",
    "import numpy as np\n",
    "from read_roi import read_roi_file\n",
    "import matplotlib.pyplot as plt\n",
    "import logging\n",
    "\n",
    "# Set up basic configuration for logging\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "\n",
    "def get_roi_coordinates(roi_file_path):\n",
    "    roi = read_roi_file(roi_file_path)\n",
    "    for box_info in roi.values():\n",
    "        if box_info['type'] == 'rectangle':\n",
    "            center_x = box_info['left'] + box_info['width'] // 2\n",
    "            center_y = box_info['top'] + box_info['height'] // 2\n",
    "            return center_x, center_y\n",
    "    return None\n",
    "\n",
    "def visualize_and_save(image, output_path, title):\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.imshow(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))\n",
    "    plt.title(title)\n",
    "    plt.axis('off')\n",
    "    plt.savefig(output_path)\n",
    "    plt.close()\n",
    "\n",
    "def extract_patches(image, center_x, center_y, ideal_patch_size, output_folder, base_filename, num_shifts=4, shift_amount=30):\n",
    "    visualization_image = image.copy()\n",
    "    shifts = [(0, 0)]  # Initial center\n",
    "    for _ in range(num_shifts):\n",
    "        shifts.extend([\n",
    "            (shift_amount, 0),  # right\n",
    "            (-shift_amount, 0), # left\n",
    "            (0, shift_amount),  # down\n",
    "            (0, -shift_amount)  # up\n",
    "        ])\n",
    "\n",
    "    for i, (shift_x, shift_y) in enumerate(shifts):\n",
    "        sp_start_x = max(center_x + shift_x - ideal_patch_size[1] // 2, 0)\n",
    "        sp_start_y = max(center_y + shift_y - ideal_patch_size[0] // 2, 0)\n",
    "        sp_end_x = min(sp_start_x + ideal_patch_size[1], image.shape[1])\n",
    "        sp_end_y = min(sp_start_y + ideal_patch_size[0], image.shape[0])\n",
    "\n",
    "        patch = image[sp_start_y:sp_end_y, sp_start_x:sp_end_x]\n",
    "        patch_name = f\"{base_filename}_patch_{i}.png\"\n",
    "        cv2.imwrite(os.path.join(output_folder, patch_name), patch)\n",
    "        cv2.rectangle(visualization_image, (sp_start_x, sp_start_y), (sp_end_x, sp_end_y), (0, 255, 0), 3)\n",
    "\n",
    "    return visualization_image\n",
    "\n",
    "def extract_normal_patches(image, ideal_patch_size, output_folder, base_filename):\n",
    "    h, w, _ = image.shape\n",
    "    visualization_image = image.copy()\n",
    "    attempts = 0\n",
    "    centers = []\n",
    "\n",
    "    while len(centers) < 2 and attempts < 100:\n",
    "        center_x = random.randint(w // 4, 3 * w // 4)\n",
    "        center_y = random.randint(h // 4, 3 * h // 4)\n",
    "\n",
    "        sp_start_x = max(center_x - ideal_patch_size[1] // 2, 0)\n",
    "        sp_start_y = max(center_y - ideal_patch_size[0] // 2, 0)\n",
    "        sp_end_x = min(sp_start_x + ideal_patch_size[1], w)\n",
    "        sp_end_y = min(sp_start_y + ideal_patch_size[0], h)\n",
    "\n",
    "        if not any([sp_start_x < ex + ew and sp_end_x > ex and sp_start_y < ey + eh and sp_end_y > ey for ex, ey, ew, eh in centers]):\n",
    "            centers.append((sp_start_x, sp_start_y, sp_end_x - sp_start_x, sp_end_y - sp_start_y))\n",
    "            patch = image[sp_start_y:sp_end_y, sp_start_x:sp_end_x]\n",
    "            patch_name = f\"{base_filename}_normal_patch_{len(centers)}.png\"\n",
    "            cv2.imwrite(os.path.join(output_folder, patch_name), patch)\n",
    "            cv2.rectangle(visualization_image, (sp_start_x, sp_start_y), (sp_end_x, sp_end_y), (0, 255, 0), 3)\n",
    "        attempts += 1\n",
    "\n",
    "    return visualization_image\n",
    "\n",
    "def process_image(folder, output_folder, visualization_folder, ideal_patch_size=(275, 300), is_abnormal=True):\n",
    "    os.makedirs(output_folder, exist_ok=True)\n",
    "    os.makedirs(visualization_folder, exist_ok=True)\n",
    "\n",
    "    for filename in os.listdir(folder):\n",
    "        if filename.endswith(('.jpg', '.jpeg', '.png')):\n",
    "            image_path = os.path.join(folder, filename)\n",
    "            image = cv2.imread(image_path)\n",
    "            if image is None:\n",
    "                logging.warning(f\"Failed to read image: {image_path}\")\n",
    "                continue\n",
    "\n",
    "            base_filename = os.path.splitext(filename)[0]\n",
    "            if is_abnormal:\n",
    "                roi_path = os.path.splitext(image_path)[0] + \".roi\"\n",
    "                if os.path.exists(roi_path):\n",
    "                    center_x, center_y = get_roi_coordinates(roi_path)\n",
    "                    visualization_image = extract_patches(image, center_x, center_y, ideal_patch_size, output_folder, base_filename)\n",
    "            else:\n",
    "                visualization_image = extract_normal_patches(image, ideal_patch_size, output_folder, base_filename)\n",
    "\n",
    "            visualization_path = os.path.join(visualization_folder, f\"{base_filename}_visualization.png\")\n",
    "            visualize_and_save(visualization_image, visualization_path, \"Extracted Patches\")\n",
    "\n",
    "def process_dirs(data_dir, output_dir, visualization_dir, ideal_patch_size=(275, 300)):\n",
    "    for class_type in ['normal', 'abnormal']:\n",
    "        input_dir = os.path.join(data_dir, class_type)\n",
    "        output_sub_dir = os.path.join(output_dir, class_type)\n",
    "        visualization_sub_dir = os.path.join(visualization_dir, class_type)\n",
    "        process_image(input_dir, output_sub_dir, visualization_sub_dir, ideal_patch_size, is_abnormal=(class_type == 'abnormal'))\n",
    "\n",
    "# Example usage\n",
    "data_dir = 'Data'\n",
    "output_dir = 'output_patches_new_1'\n",
    "visualization_dir = 'visualizations_patches_new_1'\n",
    "\n",
    "process_dirs(data_dir, output_dir, visualization_dir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import cv2\n",
    "import numpy as np\n",
    "from read_roi import read_roi_file\n",
    "import matplotlib.pyplot as plt\n",
    "import logging\n",
    "\n",
    "# Set up basic configuration for logging\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "\n",
    "def get_roi_coordinates(roi_file_path):\n",
    "    roi = read_roi_file(roi_file_path)\n",
    "    for box_info in roi.values():\n",
    "        if box_info['type'] == 'rectangle':\n",
    "            center_x = box_info['left'] + box_info['width'] // 2\n",
    "            center_y = box_info['top'] + box_info['height'] // 2\n",
    "            width = box_info['width']\n",
    "            height = box_info['height']\n",
    "            return center_x, center_y, width, height\n",
    "    return None\n",
    "\n",
    "def visualize_and_save(image, output_path, title):\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.imshow(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))\n",
    "    plt.title(title)\n",
    "    plt.axis('off')\n",
    "    plt.savefig(output_path)\n",
    "    plt.close()\n",
    "\n",
    "def extract_patches(image, center_x, center_y, ideal_patch_size, output_folder, base_filename, num_shifts=4, shift_amount=30):\n",
    "    visualization_image = image.copy()\n",
    "    shifts = [(0, 0)]  # Initial center\n",
    "    for _ in range(num_shifts):\n",
    "        shifts.extend([\n",
    "            (shift_amount, 0),  # right\n",
    "            (-shift_amount, 0), # left\n",
    "            (0, shift_amount),  # down\n",
    "            (0, -shift_amount)  # up\n",
    "        ])\n",
    "\n",
    "    for i, (shift_x, shift_y) in enumerate(shifts):\n",
    "        sp_start_x = max(center_x + shift_x - ideal_patch_size[1] // 2, 0)\n",
    "        sp_start_y = max(center_y + shift_y - ideal_patch_size[0] // 2, 0)\n",
    "        sp_end_x = sp_start_x + ideal_patch_size[1]\n",
    "        sp_end_y = sp_start_y + ideal_patch_size[0]\n",
    "\n",
    "        if sp_end_x > image.shape[1] or sp_end_y > image.shape[0]:\n",
    "            continue\n",
    "\n",
    "        patch = image[sp_start_y:sp_end_y, sp_start_x:sp_end_x]\n",
    "        patch_name = f\"{base_filename}_patch_{i}.png\"\n",
    "        cv2.imwrite(os.path.join(output_folder, patch_name), patch)\n",
    "        cv2.rectangle(visualization_image, (sp_start_x, sp_start_y), (sp_end_x, sp_end_y), (0, 255, 0), 3)\n",
    "\n",
    "    return visualization_image\n",
    "\n",
    "def extract_normal_patches(image, ideal_patch_size, output_folder, base_filename, num_normal_patches=10):\n",
    "    h, w, _ = image.shape\n",
    "    visualization_image = image.copy()\n",
    "    attempts = 0\n",
    "    centers = []\n",
    "\n",
    "    while len(centers) < num_normal_patches and attempts < 100:\n",
    "        center_x = random.randint(ideal_patch_size[1] // 2, w - ideal_patch_size[1] // 2)\n",
    "        center_y = random.randint(ideal_patch_size[0] // 2, h - ideal_patch_size[0] // 2)\n",
    "\n",
    "        sp_start_x = center_x - ideal_patch_size[1] // 2\n",
    "        sp_start_y = center_y - ideal_patch_size[0] // 2\n",
    "        sp_end_x = sp_start_x + ideal_patch_size[1]\n",
    "        sp_end_y = sp_start_y + ideal_patch_size[0]\n",
    "\n",
    "        if sp_end_x > w or sp_end_y > h:\n",
    "            continue\n",
    "\n",
    "        if not any([sp_start_x < ex + ew and sp_end_x > ex and sp_start_y < ey + eh and sp_end_y > ey for ex, ey, ew, eh in centers]):\n",
    "            centers.append((sp_start_x, sp_start_y, sp_end_x - sp_start_x, sp_end_y - sp_start_y))\n",
    "            patch = image[sp_start_y:sp_end_y, sp_start_x:sp_end_x]\n",
    "            patch_name = f\"{base_filename}_normal_patch_{len(centers)}.png\"\n",
    "            cv2.imwrite(os.path.join(output_folder, patch_name), patch)\n",
    "            cv2.rectangle(visualization_image, (sp_start_x, sp_start_y), (sp_end_x, sp_end_y), (0, 255, 0), 3)\n",
    "        attempts += 1\n",
    "\n",
    "    return visualization_image\n",
    "\n",
    "def extract_normal_patches_from_abnormal(image, roi_center_x, roi_center_y, roi_width, roi_height, ideal_patch_size, output_folder, base_filename, num_normal_patches=10):\n",
    "    h, w, _ = image.shape\n",
    "    visualization_image = image.copy()\n",
    "    attempts = 0\n",
    "    centers = []\n",
    "\n",
    "    while len(centers) < num_normal_patches and attempts < 100:\n",
    "        center_x = random.randint(ideal_patch_size[1] // 2, w - ideal_patch_size[1] // 2)\n",
    "        center_y = random.randint(ideal_patch_size[0] // 2, h - ideal_patch_size[0] // 2)\n",
    "\n",
    "        sp_start_x = center_x - ideal_patch_size[1] // 2\n",
    "        sp_start_y = center_y - ideal_patch_size[0] // 2\n",
    "        sp_end_x = sp_start_x + ideal_patch_size[1]\n",
    "        sp_end_y = sp_start_y + ideal_patch_size[0]\n",
    "\n",
    "        if sp_end_x > w or sp_end_y > h:\n",
    "            continue\n",
    "\n",
    "        # Ensure the patch does not overlap with the ROI area\n",
    "        roi_start_x = roi_center_x - roi_width // 2\n",
    "        roi_start_y = roi_center_y - roi_height // 2\n",
    "        roi_end_x = roi_center_x + roi_width // 2\n",
    "        roi_end_y = roi_center_y + roi_height // 2\n",
    "\n",
    "        if not (sp_end_x > roi_start_x and sp_start_x < roi_end_x and sp_end_y > roi_start_y and sp_start_y < roi_end_y):\n",
    "            if not any([sp_start_x < ex + ew and sp_end_x > ex and sp_start_y < ey + eh and sp_end_y > ey for ex, ey, ew, eh in centers]):\n",
    "                centers.append((sp_start_x, sp_start_y, sp_end_x - sp_start_x, sp_end_y - sp_start_y))\n",
    "                patch = image[sp_start_y:sp_end_y, sp_start_x:sp_end_x]\n",
    "                patch_name = f\"{base_filename}_normal_patch_{len(centers)}.png\"\n",
    "                cv2.imwrite(os.path.join(output_folder, patch_name), patch)\n",
    "                cv2.rectangle(visualization_image, (sp_start_x, sp_start_y), (sp_end_x, sp_end_y), (0, 255, 0), 3)\n",
    "        attempts += 1\n",
    "\n",
    "    return visualization_image\n",
    "\n",
    "def process_image(folder, normal_output_folder, abnormal_output_folder, visualization_folder, ideal_patch_size=(275, 300), is_abnormal=True):\n",
    "    os.makedirs(normal_output_folder, exist_ok=True)\n",
    "    os.makedirs(abnormal_output_folder, exist_ok=True)\n",
    "    os.makedirs(visualization_folder, exist_ok=True)\n",
    "\n",
    "    for filename in os.listdir(folder):\n",
    "        if filename.endswith(('.jpg', '.jpeg', '.png')):\n",
    "            image_path = os.path.join(folder, filename)\n",
    "            image = cv2.imread(image_path)\n",
    "            if image is None:\n",
    "                logging.warning(f\"Failed to read image: {image_path}\")\n",
    "                continue\n",
    "\n",
    "            base_filename = os.path.splitext(filename)[0]\n",
    "            if is_abnormal:\n",
    "                roi_path = os.path.splitext(image_path)[0] + \".roi\"\n",
    "                if os.path.exists(roi_path):\n",
    "                    center_x, center_y, width, height = get_roi_coordinates(roi_path)\n",
    "                    visualization_image = extract_patches(image, center_x, center_y, ideal_patch_size, abnormal_output_folder, base_filename)\n",
    "                    # Extract normal patches from abnormal images\n",
    "                    normal_visualization_image = extract_normal_patches_from_abnormal(image, center_x, center_y, width, height, ideal_patch_size, normal_output_folder, base_filename, num_normal_patches=10)\n",
    "                    visualization_image = cv2.addWeighted(visualization_image, 0.5, normal_visualization_image, 0.5, 0)\n",
    "            else:\n",
    "                visualization_image = extract_normal_patches(image, ideal_patch_size, normal_output_folder, base_filename, num_normal_patches=10)\n",
    "\n",
    "            visualization_path = os.path.join(visualization_folder, f\"{base_filename}_visualization.png\")\n",
    "            visualize_and_save(visualization_image, visualization_path, \"Extracted Patches\")\n",
    "\n",
    "def process_dirs(data_dir, output_dir, visualization_dir, ideal_patch_size=(275, 300)):\n",
    "    for class_type in ['normal', 'abnormal']:\n",
    "        input_dir = os.path.join(data_dir, class_type)\n",
    "        normal_output_sub_dir = os.path.join(output_dir, 'normal')\n",
    "        abnormal_output_sub_dir = os.path.join(output_dir, 'abnormal')\n",
    "        visualization_sub_dir = os.path.join(visualization_dir, class_type)\n",
    "        process_image(input_dir, normal_output_sub_dir, abnormal_output_sub_dir, visualization_sub_dir, ideal_patch_size, is_abnormal=(class_type == 'abnormal'))\n",
    "\n",
    "# Example usage\n",
    "data_dir = 'Data'\n",
    "output_dir = 'output_patches_new_2'\n",
    "visualization_dir = 'visualizations_patches_new_2'\n",
    "\n",
    "process_dirs(data_dir, output_dir, visualization_dir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed processing. Check the output directory: Processed_Images_pred_700\n",
      "Accuracy: 0.8293\n",
      "Precision: 0.7733\n",
      "Recall: 0.9779\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "from pytorch_grad_cam import GradCAMPlusPlus\n",
    "from pytorch_grad_cam.utils.model_targets import ClassifierOutputTarget\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score\n",
    "import torchvision.models as models\n",
    "\n",
    "# Custom dataset class\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, images, labels, transform=None):\n",
    "        self.images = images\n",
    "        self.labels = labels\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image = self.images[idx]\n",
    "        label = self.labels[idx]\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        return image, label\n",
    "\n",
    "# Define transformations for testing\n",
    "test_transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])\n",
    "\n",
    "# Load your pre-trained PyTorch models for patches and full images\n",
    "model_patch = torch.load('Models/denseNet_redo_patches', map_location=torch.device('cpu'))\n",
    "model_patch.eval()\n",
    "model_full = torch.load('Models/denseNet_redo_full_images', map_location=torch.device('cpu'))\n",
    "model_full.eval()\n",
    "\n",
    "# Transformation pipeline for image preprocessing\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "def get_heatmap(input_tensor, model, target_layers):\n",
    "    cam = GradCAMPlusPlus(model=model, target_layers=target_layers)\n",
    "    pred = model(input_tensor)\n",
    "    _, predicted_class = pred.max(1)\n",
    "    targets = [ClassifierOutputTarget(predicted_class.item())]\n",
    "    grayscale_cam = cam(input_tensor=input_tensor, targets=targets)[0, :]\n",
    "    return grayscale_cam, predicted_class.item(), torch.softmax(pred, dim=1)[0, predicted_class].item()\n",
    "\n",
    "def adaptive_thresholding(heatmap, predicted_label):\n",
    "    \"\"\"Determine the threshold based on the predicted label.\n",
    "    - If the label is abnormal (1), apply a stricter threshold (top 25% of values).\n",
    "    - If the label is normal (0), apply a broader threshold (top 50% of values).\"\"\"\n",
    "    threshold_percentile = 75 if predicted_label == 1 else 95\n",
    "    threshold_value = np.percentile(heatmap, threshold_percentile)\n",
    "    return (heatmap >= threshold_value).astype('uint8')\n",
    "\n",
    "def detect_features_in_channel(channel, mask=None):\n",
    "    features = cv2.goodFeaturesToTrack(channel, mask=mask, maxCorners=100, qualityLevel=0.01, minDistance=150)\n",
    "    return np.int0(features).reshape(-1, 2) if features is not None else np.array([])\n",
    "\n",
    "def weighted_voting(patch_predictions, patch_confidences, image_pred, image_conf):\n",
    "    \"\"\"Perform weighted voting based on the confidence scores.\"\"\"\n",
    "    vote_count = {0: 0, 1: 0}  # Initialize voting counters for each class\n",
    "\n",
    "    # Weight adjustments based on the full image prediction\n",
    "    image_weight = 5\n",
    "    if image_pred == 1:\n",
    "        vote_count[1] += image_conf * image_weight\n",
    "    else:\n",
    "        vote_count[0] += (1 - image_conf) * image_weight\n",
    "\n",
    "    # Weight adjustments based on patch predictions\n",
    "    for pred, conf in zip(patch_predictions, patch_confidences):\n",
    "        patch_weight = 2 if conf > 0.8 else 1  # Give higher weight to high confidence abnormal patches\n",
    "        if pred == 1:\n",
    "            vote_count[1] += conf * patch_weight\n",
    "        else:\n",
    "            vote_count[0] += (1 - conf) * patch_weight\n",
    "\n",
    "    return 1 if vote_count[1] > vote_count[0] else 0\n",
    "\n",
    "def extract_and_visualize(image_path, label, model_patch, model_full, transform, output_dir):\n",
    "    image = Image.open(image_path).convert('RGB')\n",
    "    image_np = np.array(image)\n",
    "    input_tensor = transform(image).unsqueeze(0)\n",
    "    \n",
    "    if torch.cuda.is_available():\n",
    "        input_tensor = input_tensor.cuda()\n",
    "\n",
    "    # Full image attention map\n",
    "    heatmap_full, pred_full, conf_full = get_heatmap(input_tensor, model_full, [model_full.features.norm5])\n",
    "    heatmap_resized_full = cv2.resize(heatmap_full, (image_np.shape[1], image_np.shape[0]))\n",
    "    heatmap_normalized_full = heatmap_resized_full / np.max(heatmap_resized_full)\n",
    "\n",
    "    # Apply adaptive thresholding based on predicted label\n",
    "    binary_mask_full = adaptive_thresholding(heatmap_normalized_full, pred_full)\n",
    "\n",
    "    # Overlay Image\n",
    "    overlay_img_full = cv2.addWeighted(image_np, 0.6, cv2.applyColorMap(np.uint8(255 * heatmap_normalized_full), cv2.COLORMAP_JET), 0.4, 0)\n",
    "\n",
    "    # Detect salient points\n",
    "    salient_points_all = detect_features_in_channel(cv2.cvtColor(image_np, cv2.COLOR_RGB2GRAY))  # Without mask\n",
    "    salient_points_filtered = detect_features_in_channel(cv2.cvtColor(image_np, cv2.COLOR_RGB2GRAY), binary_mask_full)  # With mask\n",
    "\n",
    "    # Image with all salient points\n",
    "    image_with_all_salient_points = image_np.copy()\n",
    "    for pt in salient_points_all:\n",
    "        cv2.circle(image_with_all_salient_points, (pt[0], pt[1]), 5, (0, 0, 255), 5)\n",
    "\n",
    "    # Image with filtered salient points\n",
    "    image_with_salient_points = image_np.copy()\n",
    "    for pt in salient_points_filtered:\n",
    "        cv2.circle(image_with_salient_points, (pt[0], pt[1]), 5, (0, 0, 255), 5)\n",
    "\n",
    "    # Image with patch classifications\n",
    "    image_with_classified_patches = image_np.copy()\n",
    "    patch_predictions = []\n",
    "    patch_confidences = []\n",
    "    for pt in salient_points_filtered:\n",
    "        top_left_x = max(pt[0] - 137, 0)\n",
    "        top_left_y = max(pt[1] - 150, 0)\n",
    "        bottom_right_x = min(top_left_x + 275, image_with_classified_patches.shape[1])\n",
    "        bottom_right_y = min(top_left_y + 300, image_with_classified_patches.shape[0])\n",
    "\n",
    "        patch = image_with_classified_patches[top_left_y:bottom_right_y, top_left_x:bottom_right_x]\n",
    "        patch_tensor = torch.from_numpy(np.transpose(cv2.resize(patch, (224, 224)), (2, 0, 1)).astype('float32') / 255.0).unsqueeze(0)\n",
    "        if torch.cuda.is_available():\n",
    "            patch_tensor = patch_tensor.cuda()\n",
    "        with torch.no_grad():\n",
    "            output = model_patch(patch_tensor)\n",
    "            prob = torch.softmax(output, dim=1)\n",
    "            pred = torch.argmax(prob, dim=1)\n",
    "            conf = prob[0][pred].item()\n",
    "\n",
    "        patch_predictions.append(pred.item())\n",
    "        patch_confidences.append(conf)\n",
    "\n",
    "        color = (0, 255, 0) if pred.item() == 1 else (0, 0, 255)\n",
    "        cv2.rectangle(image_with_classified_patches, (top_left_x, top_left_y), (bottom_right_x, bottom_right_y), color, 2)\n",
    "        text = f\"{conf:.2f}\"  # Confidence score\n",
    "        cv2.putText(image_with_classified_patches, text, (top_left_x, top_left_y - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.9, (255, 0, 0), 2)\n",
    "\n",
    "    final_prediction = weighted_voting(patch_predictions, patch_confidences, pred_full, conf_full)\n",
    "\n",
    "    # 3x2 Grid Visualization\n",
    "    fig, axs = plt.subplots(3, 2, figsize=(16, 24))\n",
    "    axs[0, 0].imshow(heatmap_normalized_full, cmap='jet')\n",
    "    axs[0, 0].axis('off')\n",
    "    axs[0, 0].set_title(f'Heatmap Full (DenseNet) - Pred: {pred_full}, GT: {label}')\n",
    "\n",
    "    axs[0, 1].imshow(overlay_img_full)\n",
    "    axs[0, 1].axis('off')\n",
    "    axs[0, 1].set_title('Overlay Image Full')\n",
    "\n",
    "    axs[1, 0].imshow(image_with_all_salient_points)\n",
    "    axs[1, 0].axis('off')\n",
    "    axs[1, 0].set_title('All Salient Points')\n",
    "\n",
    "    axs[1, 1].imshow(image_with_salient_points)\n",
    "    axs[1, 1].axis('off')\n",
    "    axs[1, 1].set_title('Filtered Salient Points')\n",
    "\n",
    "    axs[2, 0].imshow(image_with_classified_patches)\n",
    "    axs[2, 0].axis('off')\n",
    "    axs[2, 0].set_title('Patch Classifications')\n",
    "\n",
    "    # Leave the last grid empty if not needed\n",
    "    axs[2, 1].axis('off')\n",
    "\n",
    "    output_filename = f\"{os.path.splitext(os.path.basename(image_path))[0]}_composite.png\"\n",
    "    plt.savefig(os.path.join(output_dir, output_filename))\n",
    "    plt.close()\n",
    "\n",
    "    return final_prediction, label\n",
    "\n",
    "# Directory and processing setup\n",
    "root_dir = 'Data/Testing/Images'\n",
    "output_dir = 'Processed_Images_pred_700'\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "all_predictions = []\n",
    "all_labels = []\n",
    "\n",
    "for subfolder in ['normal_testing_images', 'abnormal_testing_images']:\n",
    "    folder_path = os.path.join(root_dir, subfolder)\n",
    "    label = 0 if subfolder == 'normal_testing_images' else 1\n",
    "    for image_file in os.listdir(folder_path):\n",
    "        if image_file.lower().endswith(('.png', '.jpg', '.jpeg')):\n",
    "            image_path = os.path.join(folder_path, image_file)\n",
    "            final_prediction, true_label = extract_and_visualize(image_path, label, model_patch, model_full, transform, output_dir)\n",
    "            all_predictions.append(final_prediction)\n",
    "            all_labels.append(true_label)\n",
    "\n",
    "# Calculate and print accuracy, precision, and recall\n",
    "accuracy = accuracy_score(all_labels, all_predictions)\n",
    "precision = precision_score(all_labels, all_predictions)\n",
    "recall = recall_score(all_labels, all_predictions)\n",
    "\n",
    "print(f\"Completed processing. Check the output directory: {output_dir}\")\n",
    "print(f\"Accuracy: {accuracy:.4f}\")\n",
    "print(f\"Precision: {precision:.4f}\")\n",
    "print(f\"Recall: {recall:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed processing. Check the output directory: Processed_Images_pred_correct and Processed_Images_pred_incorrect\n",
      "Accuracy: 0.8293\n",
      "Precision: 0.7733\n",
      "Recall: 0.9779\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "from pytorch_grad_cam import GradCAMPlusPlus\n",
    "from pytorch_grad_cam.utils.model_targets import ClassifierOutputTarget\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score\n",
    "import torchvision.models as models\n",
    "\n",
    "# Custom dataset class\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, images, labels, transform=None):\n",
    "        self.images = images\n",
    "        self.labels = labels\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image = self.images[idx]\n",
    "        label = self.labels[idx]\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        return image, label\n",
    "\n",
    "# Define transformations for testing\n",
    "test_transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])\n",
    "\n",
    "# Load your pre-trained PyTorch models for patches and full images\n",
    "model_patch = torch.load('Models/denseNet_redo_patches', map_location=torch.device('cpu'))\n",
    "model_patch.eval()\n",
    "model_full = torch.load('Models/denseNet_redo_full_images', map_location=torch.device('cpu'))\n",
    "model_full.eval()\n",
    "\n",
    "# Transformation pipeline for image preprocessing\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "def get_heatmap(input_tensor, model, target_layers):\n",
    "    cam = GradCAMPlusPlus(model=model, target_layers=target_layers)\n",
    "    pred = model(input_tensor)\n",
    "    _, predicted_class = pred.max(1)\n",
    "    targets = [ClassifierOutputTarget(predicted_class.item())]\n",
    "    grayscale_cam = cam(input_tensor=input_tensor, targets=targets)[0, :]\n",
    "    return grayscale_cam, predicted_class.item(), torch.softmax(pred, dim=1)[0, predicted_class].item()\n",
    "\n",
    "def adaptive_thresholding(heatmap, predicted_label):\n",
    "    \"\"\"Determine the threshold based on the predicted label.\n",
    "    - If the label is abnormal (1), apply a stricter threshold (top 25% of values).\n",
    "    - If the label is normal (0), apply a broader threshold (top 50% of values).\"\"\"\n",
    "    threshold_percentile = 75 if predicted_label == 1 else 95\n",
    "    threshold_value = np.percentile(heatmap, threshold_percentile)\n",
    "    return (heatmap >= threshold_value).astype('uint8')\n",
    "\n",
    "def detect_features_in_channel(channel, mask=None):\n",
    "    features = cv2.goodFeaturesToTrack(channel, mask=mask, maxCorners=100, qualityLevel=0.01, minDistance=150)\n",
    "    return np.int0(features).reshape(-1, 2) if features is not None else np.array([])\n",
    "\n",
    "def weighted_voting(patch_predictions, patch_confidences, image_pred, image_conf):\n",
    "    \"\"\"Perform weighted voting based on the confidence scores.\"\"\"\n",
    "    vote_count = {0: 0, 1: 0}  # Initialize voting counters for each class\n",
    "\n",
    "    # Weight adjustments based on the full image prediction\n",
    "    image_weight = 5\n",
    "    if image_pred == 1:\n",
    "        vote_count[1] += image_conf * image_weight\n",
    "    else:\n",
    "        vote_count[0] += (1 - image_conf) * image_weight\n",
    "\n",
    "    # Weight adjustments based on patch predictions\n",
    "    for pred, conf in zip(patch_predictions, patch_confidences):\n",
    "        patch_weight = 2 if conf > 0.8 else 1  # Give higher weight to high confidence abnormal patches\n",
    "        if pred == 1:\n",
    "            vote_count[1] += conf * patch_weight\n",
    "        else:\n",
    "            vote_count[0] += (1 - conf) * patch_weight\n",
    "\n",
    "    return 1 if vote_count[1] > vote_count[0] else 0\n",
    "\n",
    "def extract_and_visualize(image_path, label, model_patch, model_full, transform, correct_dir, incorrect_dir):\n",
    "    image = Image.open(image_path).convert('RGB')\n",
    "    image_np = np.array(image)\n",
    "    input_tensor = transform(image).unsqueeze(0)\n",
    "    \n",
    "    if torch.cuda.is_available():\n",
    "        input_tensor = input_tensor.cuda()\n",
    "\n",
    "    # Full image attention map\n",
    "    heatmap_full, pred_full, conf_full = get_heatmap(input_tensor, model_full, [model_full.features.norm5])\n",
    "    heatmap_resized_full = cv2.resize(heatmap_full, (image_np.shape[1], image_np.shape[0]))\n",
    "    heatmap_normalized_full = heatmap_resized_full / np.max(heatmap_resized_full)\n",
    "\n",
    "    # Apply adaptive thresholding based on predicted label\n",
    "    binary_mask_full = adaptive_thresholding(heatmap_normalized_full, pred_full)\n",
    "\n",
    "    # Overlay Image\n",
    "    overlay_img_full = cv2.addWeighted(image_np, 0.6, cv2.applyColorMap(np.uint8(255 * heatmap_normalized_full), cv2.COLORMAP_JET), 0.4, 0)\n",
    "\n",
    "    # Detect salient points\n",
    "    salient_points_all = detect_features_in_channel(cv2.cvtColor(image_np, cv2.COLOR_RGB2GRAY))  # Without mask\n",
    "    salient_points_filtered = detect_features_in_channel(cv2.cvtColor(image_np, cv2.COLOR_RGB2GRAY), binary_mask_full)  # With mask\n",
    "\n",
    "    # Image with all salient points\n",
    "    image_with_all_salient_points = image_np.copy()\n",
    "    for pt in salient_points_all:\n",
    "        cv2.circle(image_with_all_salient_points, (pt[0], pt[1]), 5, (0, 0, 255), 5)\n",
    "\n",
    "    # Image with filtered salient points\n",
    "    image_with_salient_points = image_np.copy()\n",
    "    for pt in salient_points_filtered:\n",
    "        cv2.circle(image_with_salient_points, (pt[0], pt[1]), 5, (0, 0, 255), 5)\n",
    "\n",
    "    # Image with patch classifications\n",
    "    image_with_classified_patches = image_np.copy()\n",
    "    patch_predictions = []\n",
    "    patch_confidences = []\n",
    "    for pt in salient_points_filtered:\n",
    "        top_left_x = max(pt[0] - 137, 0)\n",
    "        top_left_y = max(pt[1] - 150, 0)\n",
    "        bottom_right_x = min(top_left_x + 275, image_with_classified_patches.shape[1])\n",
    "        bottom_right_y = min(top_left_y + 300, image_with_classified_patches.shape[0])\n",
    "\n",
    "        patch = image_with_classified_patches[top_left_y:bottom_right_y, top_left_x:bottom_right_x]\n",
    "        patch_tensor = torch.from_numpy(np.transpose(cv2.resize(patch, (224, 224)), (2, 0, 1)).astype('float32') / 255.0).unsqueeze(0)\n",
    "        if torch.cuda.is_available():\n",
    "            patch_tensor = patch_tensor.cuda()\n",
    "        with torch.no_grad():\n",
    "            output = model_patch(patch_tensor)\n",
    "            prob = torch.softmax(output, dim=1)\n",
    "            pred = torch.argmax(prob, dim=1)\n",
    "            conf = prob[0][pred].item()\n",
    "\n",
    "        patch_predictions.append(pred.item())\n",
    "        patch_confidences.append(conf)\n",
    "\n",
    "        color = (0, 255, 0) if pred.item() == 1 else (0, 0, 255)\n",
    "        cv2.rectangle(image_with_classified_patches, (top_left_x, top_left_y), (bottom_right_x, bottom_right_y), color, 2)\n",
    "        text = f\"{conf:.2f}\"  # Confidence score\n",
    "        cv2.putText(image_with_classified_patches, text, (top_left_x, top_left_y - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.9, (255, 0, 0), 2)\n",
    "\n",
    "    final_prediction = weighted_voting(patch_predictions, patch_confidences, pred_full, conf_full)\n",
    "\n",
    "    # 3x2 Grid Visualization\n",
    "    fig, axs = plt.subplots(3, 2, figsize=(16, 24))\n",
    "    axs[0, 0].imshow(heatmap_normalized_full, cmap='jet')\n",
    "    axs[0, 0].axis('off')\n",
    "    axs[0, 0].set_title(f'Heatmap Full (DenseNet) - Pred: {pred_full}, GT: {label}')\n",
    "\n",
    "    axs[0, 1].imshow(overlay_img_full)\n",
    "    axs[0, 1].axis('off')\n",
    "    axs[0, 1].set_title('Overlay Image Full')\n",
    "\n",
    "    axs[1, 0].imshow(image_with_all_salient_points)\n",
    "    axs[1, 0].axis('off')\n",
    "    axs[1, 0].set_title('All Salient Points')\n",
    "\n",
    "    axs[1, 1].imshow(image_with_salient_points)\n",
    "    axs[1, 1].axis('off')\n",
    "    axs[1, 1].set_title('Filtered Salient Points')\n",
    "\n",
    "    axs[2, 0].imshow(image_with_classified_patches)\n",
    "    axs[2, 0].axis('off')\n",
    "    axs[2, 0].set_title('Patch Classifications')\n",
    "\n",
    "    # Leave the last grid empty if not needed\n",
    "    axs[2, 1].axis('off')\n",
    "\n",
    "    if final_prediction == label:\n",
    "        output_filename = os.path.join(correct_dir, f\"{os.path.splitext(os.path.basename(image_path))[0]}_composite.png\")\n",
    "    else:\n",
    "        output_filename = os.path.join(incorrect_dir, f\"{os.path.splitext(os.path.basename(image_path))[0]}_composite.png\")\n",
    "\n",
    "    plt.savefig(output_filename)\n",
    "    plt.close()\n",
    "\n",
    "    return final_prediction, label\n",
    "\n",
    "# Directory and processing setup\n",
    "root_dir = 'Data/Testing/Images'\n",
    "output_dir_correct = 'Processed_Images_pred_correct'\n",
    "output_dir_incorrect = 'Processed_Images_pred_incorrect'\n",
    "os.makedirs(output_dir_correct, exist_ok=True)\n",
    "os.makedirs(output_dir_incorrect, exist_ok=True)\n",
    "\n",
    "all_predictions = []\n",
    "all_labels = []\n",
    "\n",
    "for subfolder in ['normal_testing_images', 'abnormal_testing_images']:\n",
    "    folder_path = os.path.join(root_dir, subfolder)\n",
    "    label = 0 if subfolder == 'normal_testing_images' else 1\n",
    "    for image_file in os.listdir(folder_path):\n",
    "        if image_file.lower().endswith(('.png', '.jpg', '.jpeg')):\n",
    "            image_path = os.path.join(folder_path, image_file)\n",
    "            final_prediction, true_label = extract_and_visualize(image_path, label, model_patch, model_full, transform, output_dir_correct, output_dir_incorrect)\n",
    "            all_predictions.append(final_prediction)\n",
    "            all_labels.append(true_label)\n",
    "\n",
    "# Calculate and print accuracy, precision, and recall\n",
    "accuracy = accuracy_score(all_labels, all_predictions)\n",
    "precision = precision_score(all_labels, all_predictions)\n",
    "recall = recall_score(all_labels, all_predictions)\n",
    "\n",
    "print(f\"Completed processing. Check the output directory: {output_dir_correct} and {output_dir_incorrect}\")\n",
    "print(f\"Accuracy: {accuracy:.4f}\")\n",
    "print(f\"Precision: {precision:.4f}\")\n",
    "print(f\"Recall: {recall:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed processing. Check the output directories: Processed_Images_pred_correct, Processed_Images_pred_incorrect, and Processed_Patches\n",
      "Accuracy: 0.8293\n",
      "Precision: 0.7733\n",
      "Recall: 0.9779\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "from pytorch_grad_cam import GradCAMPlusPlus\n",
    "from pytorch_grad_cam.utils.model_targets import ClassifierOutputTarget\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score\n",
    "import torchvision.models as models\n",
    "\n",
    "# Custom dataset class\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, images, labels, transform=None):\n",
    "        self.images = images\n",
    "        self.labels = labels\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image = self.images[idx]\n",
    "        label = self.labels[idx]\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        return image, label\n",
    "\n",
    "# Define transformations for testing\n",
    "test_transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])\n",
    "\n",
    "# Load your pre-trained PyTorch models for patches and full images\n",
    "model_patch = torch.load('Models/denseNet_redo_patches', map_location=torch.device('cpu'))\n",
    "model_patch.eval()\n",
    "model_full = torch.load('Models/denseNet_redo_full_images', map_location=torch.device('cpu'))\n",
    "model_full.eval()\n",
    "\n",
    "# Transformation pipeline for image preprocessing\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "def get_heatmap(input_tensor, model, target_layers):\n",
    "    cam = GradCAMPlusPlus(model=model, target_layers=target_layers)\n",
    "    pred = model(input_tensor)\n",
    "    _, predicted_class = pred.max(1)\n",
    "    targets = [ClassifierOutputTarget(predicted_class.item())]\n",
    "    grayscale_cam = cam(input_tensor=input_tensor, targets=targets)[0, :]\n",
    "    return grayscale_cam, predicted_class.item(), torch.softmax(pred, dim=1)[0, predicted_class].item()\n",
    "\n",
    "def adaptive_thresholding(heatmap, predicted_label):\n",
    "    \"\"\"Determine the threshold based on the predicted label.\n",
    "    - If the label is abnormal (1), apply a stricter threshold (top 25% of values).\n",
    "    - If the label is normal (0), apply a broader threshold (top 50% of values).\"\"\"\n",
    "    threshold_percentile = 75 if predicted_label == 1 else 95\n",
    "    threshold_value = np.percentile(heatmap, threshold_percentile)\n",
    "    return (heatmap >= threshold_value).astype('uint8')\n",
    "\n",
    "def detect_features_in_channel(channel, mask=None):\n",
    "    features = cv2.goodFeaturesToTrack(channel, mask=mask, maxCorners=100, qualityLevel=0.01, minDistance=150)\n",
    "    return np.int0(features).reshape(-1, 2) if features is not None else np.array([])\n",
    "\n",
    "def weighted_voting(patch_predictions, patch_confidences, image_pred, image_conf):\n",
    "    \"\"\"Perform weighted voting based on the confidence scores.\"\"\"\n",
    "    vote_count = {0: 0, 1: 0}  # Initialize voting counters for each class\n",
    "\n",
    "    # Weight adjustments based on the full image prediction\n",
    "    image_weight = 5\n",
    "    if image_pred == 1:\n",
    "        vote_count[1] += image_conf * image_weight\n",
    "    else:\n",
    "        vote_count[0] += (1 - image_conf) * image_weight\n",
    "\n",
    "    # Weight adjustments based on patch predictions\n",
    "    for pred, conf in zip(patch_predictions, patch_confidences):\n",
    "        patch_weight = 2 if conf > 0.8 else 1  # Give higher weight to high confidence abnormal patches\n",
    "        if pred == 1:\n",
    "            vote_count[1] += conf * patch_weight\n",
    "        else:\n",
    "            vote_count[0] += (1 - conf) * patch_weight\n",
    "\n",
    "    return 1 if vote_count[1] > vote_count[0] else 0\n",
    "\n",
    "def extract_and_save_patches(image_path, extracted_patches, patch_predictions, patch_confidences, output_dir_patches):\n",
    "    base_filename = os.path.splitext(os.path.basename(image_path))[0]\n",
    "    patch_dir = os.path.join(output_dir_patches, base_filename)\n",
    "    os.makedirs(patch_dir, exist_ok=True)\n",
    "\n",
    "    for i, (patch, pred, conf) in enumerate(zip(extracted_patches, patch_predictions, patch_confidences)):\n",
    "        patch_filename = os.path.join(patch_dir, f\"patch_{i}_pred_{pred}_conf_{conf:.2f}.png\")\n",
    "        patch.save(patch_filename)\n",
    "\n",
    "def extract_and_visualize(image_path, label, model_patch, model_full, transform, correct_dir, incorrect_dir, output_dir_patches):\n",
    "    image = Image.open(image_path).convert('RGB')\n",
    "    image_np = np.array(image)\n",
    "    input_tensor = transform(image).unsqueeze(0)\n",
    "    \n",
    "    if torch.cuda.is_available():\n",
    "        input_tensor = input_tensor.cuda()\n",
    "\n",
    "    # Full image attention map\n",
    "    heatmap_full, pred_full, conf_full = get_heatmap(input_tensor, model_full, [model_full.features.norm5])\n",
    "    heatmap_resized_full = cv2.resize(heatmap_full, (image_np.shape[1], image_np.shape[0]))\n",
    "    heatmap_normalized_full = heatmap_resized_full / np.max(heatmap_resized_full)\n",
    "\n",
    "    # Apply adaptive thresholding based on predicted label\n",
    "    binary_mask_full = adaptive_thresholding(heatmap_normalized_full, pred_full)\n",
    "\n",
    "    # Overlay Image\n",
    "    overlay_img_full = cv2.addWeighted(image_np, 0.6, cv2.applyColorMap(np.uint8(255 * heatmap_normalized_full), cv2.COLORMAP_JET), 0.4, 0)\n",
    "\n",
    "    # Detect salient points\n",
    "    salient_points_all = detect_features_in_channel(cv2.cvtColor(image_np, cv2.COLOR_RGB2GRAY))  # Without mask\n",
    "    salient_points_filtered = detect_features_in_channel(cv2.cvtColor(image_np, cv2.COLOR_RGB2GRAY), binary_mask_full)  # With mask\n",
    "\n",
    "    # Image with all salient points\n",
    "    image_with_all_salient_points = image_np.copy()\n",
    "    for pt in salient_points_all:\n",
    "        cv2.circle(image_with_all_salient_points, (pt[0], pt[1]), 5, (0, 0, 255), 5)\n",
    "\n",
    "    # Image with filtered salient points\n",
    "    image_with_salient_points = image_np.copy()\n",
    "    for pt in salient_points_filtered:\n",
    "        cv2.circle(image_with_salient_points, (pt[0], pt[1]), 5, (0, 0, 255), 5)\n",
    "\n",
    "    # Image with patch classifications\n",
    "    image_with_classified_patches = image_np.copy()\n",
    "    patch_predictions = []\n",
    "    patch_confidences = []\n",
    "    extracted_patches = []  # Store patches for saving\n",
    "    for pt in salient_points_filtered:\n",
    "        top_left_x = max(pt[0] - 137, 0)\n",
    "        top_left_y = max(pt[1] - 150, 0)\n",
    "        bottom_right_x = min(top_left_x + 275, image_with_classified_patches.shape[1])\n",
    "        bottom_right_y = min(top_left_y + 300, image_with_classified_patches.shape[0])\n",
    "\n",
    "        patch = image_with_classified_patches[top_left_y:bottom_right_y, top_left_x:bottom_right_x]\n",
    "        extracted_patches.append(Image.fromarray(patch))  # Add patch to list\n",
    "        patch_tensor = torch.from_numpy(np.transpose(cv2.resize(patch, (224, 224)), (2, 0, 1)).astype('float32') / 255.0).unsqueeze(0)\n",
    "        if torch.cuda.is_available():\n",
    "            patch_tensor = patch_tensor.cuda()\n",
    "        with torch.no_grad():\n",
    "            output = model_patch(patch_tensor)\n",
    "            prob = torch.softmax(output, dim=1)\n",
    "            pred = torch.argmax(prob, dim=1)\n",
    "            conf = prob[0][pred].item()\n",
    "\n",
    "        patch_predictions.append(pred.item())\n",
    "        patch_confidences.append(conf)\n",
    "\n",
    "        color = (0, 255, 0) if pred.item() == 1 else (0, 0, 255)\n",
    "        cv2.rectangle(image_with_classified_patches, (top_left_x, top_left_y), (bottom_right_x, bottom_right_y), color, 2)\n",
    "        text = f\"{conf:.2f}\"  # Confidence score\n",
    "        cv2.putText(image_with_classified_patches, text, (top_left_x, top_left_y - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.9, (255, 0, 0), 2)\n",
    "\n",
    "    final_prediction = weighted_voting(patch_predictions, patch_confidences, pred_full, conf_full)\n",
    "\n",
    "    # Save extracted patches with predictions and confidences\n",
    "    extract_and_save_patches(image_path, extracted_patches, patch_predictions, patch_confidences, output_dir_patches)\n",
    "\n",
    "    # 3x2 Grid Visualization\n",
    "    fig, axs = plt.subplots(3, 2, figsize=(16, 24))\n",
    "    axs[0, 0].imshow(heatmap_normalized_full, cmap='jet')\n",
    "    axs[0, 0].axis('off')\n",
    "    axs[0, 0].set_title(f'Heatmap Full (DenseNet) - Pred: {pred_full}, GT: {label}')\n",
    "\n",
    "    axs[0, 1].imshow(overlay_img_full)\n",
    "    axs[0, 1].axis('off')\n",
    "    axs[0, 1].set_title('Overlay Image Full')\n",
    "\n",
    "    axs[1, 0].imshow(image_with_all_salient_points)\n",
    "    axs[1, 0].axis('off')\n",
    "    axs[1, 0].set_title('All Salient Points')\n",
    "\n",
    "    axs[1, 1].imshow(image_with_salient_points)\n",
    "    axs[1, 1].axis('off')\n",
    "    axs[1, 1].set_title('Filtered Salient Points')\n",
    "\n",
    "    axs[2, 0].imshow(image_with_classified_patches)\n",
    "    axs[2, 0].axis('off')\n",
    "    axs[2, 0].set_title('Patch Classifications')\n",
    "\n",
    "    # Leave the last grid empty if not needed\n",
    "    axs[2, 1].axis('off')\n",
    "\n",
    "    if final_prediction == label:\n",
    "        output_filename = os.path.join(correct_dir, f\"{os.path.splitext(os.path.basename(image_path))[0]}_composite.png\")\n",
    "    else:\n",
    "        output_filename = os.path.join(incorrect_dir, f\"{os.path.splitext(os.path.basename(image_path))[0]}_composite.png\")\n",
    "\n",
    "    plt.savefig(output_filename)\n",
    "    plt.close()\n",
    "\n",
    "    return final_prediction, label\n",
    "\n",
    "# Directory and processing setup\n",
    "root_dir = 'Data/Testing/Images'\n",
    "output_dir_correct = 'Processed_Images_pred_correct'\n",
    "output_dir_incorrect = 'Processed_Images_pred_incorrect'\n",
    "output_dir_patches = 'Processed_Patches'\n",
    "os.makedirs(output_dir_correct, exist_ok=True)\n",
    "os.makedirs(output_dir_incorrect, exist_ok=True)\n",
    "os.makedirs(output_dir_patches, exist_ok=True)\n",
    "\n",
    "all_predictions = []\n",
    "all_labels = []\n",
    "\n",
    "for subfolder in ['normal_testing_images', 'abnormal_testing_images']:\n",
    "    folder_path = os.path.join(root_dir, subfolder)\n",
    "    label = 0 if subfolder == 'normal_testing_images' else 1\n",
    "    for image_file in os.listdir(folder_path):\n",
    "        if image_file.lower().endswith(('.png', '.jpg', '.jpeg')):\n",
    "            image_path = os.path.join(folder_path, image_file)\n",
    "            final_prediction, true_label = extract_and_visualize(image_path, label, model_patch, model_full, transform, output_dir_correct, output_dir_incorrect, output_dir_patches)\n",
    "            all_predictions.append(final_prediction)\n",
    "            all_labels.append(true_label)\n",
    "\n",
    "# Calculate and print accuracy, precision, and recall\n",
    "accuracy = accuracy_score(all_labels, all_predictions)\n",
    "precision = precision_score(all_labels, all_predictions)\n",
    "recall = recall_score(all_labels, all_predictions)\n",
    "\n",
    "print(f\"Completed processing. Check the output directories: {output_dir_correct}, {output_dir_incorrect}, and {output_dir_patches}\")\n",
    "print(f\"Accuracy: {accuracy:.4f}\")\n",
    "print(f\"Precision: {precision:.4f}\")\n",
    "print(f\"Recall: {recall:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed processing. Check the output directories: Processed_Images_pred_correct_3, Processed_Images_pred_incorrect_3, and Processed_Patches_3\n",
      "Accuracy: 0.8130\n",
      "Precision: 0.7528\n",
      "Recall: 0.9853\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "from pytorch_grad_cam import GradCAMPlusPlus\n",
    "from pytorch_grad_cam.utils.model_targets import ClassifierOutputTarget\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score\n",
    "import torchvision.models as models\n",
    "\n",
    "# Custom dataset class\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, images, labels, transform=None):\n",
    "        self.images = images\n",
    "        self.labels = labels\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image = self.images[idx]\n",
    "        label = self.labels[idx]\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        return image, label\n",
    "\n",
    "# Define transformations for testing\n",
    "test_transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])\n",
    "\n",
    "# Load your pre-trained PyTorch models for patches and full images\n",
    "model_patch = torch.load('Models/Patch_Model_All_Data_DenseNet', map_location=torch.device('cpu'))\n",
    "model_patch.eval()\n",
    "model_full = torch.load('Models/denseNet_redo_full_images', map_location=torch.device('cpu'))\n",
    "model_full.eval()\n",
    "\n",
    "# Transformation pipeline for image preprocessing\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "def get_heatmap(input_tensor, model, target_layers):\n",
    "    cam = GradCAMPlusPlus(model=model, target_layers=target_layers)\n",
    "    pred = model(input_tensor)\n",
    "    _, predicted_class = pred.max(1)\n",
    "    targets = [ClassifierOutputTarget(predicted_class.item())]\n",
    "    grayscale_cam = cam(input_tensor=input_tensor, targets=targets)[0, :]\n",
    "    return grayscale_cam, predicted_class.item(), torch.softmax(pred, dim=1)[0, predicted_class].item()\n",
    "\n",
    "def adaptive_thresholding(heatmap, predicted_label):\n",
    "    \"\"\"Determine the threshold based on the predicted label.\n",
    "    - If the label is abnormal (1), apply a stricter threshold (top 25% of values).\n",
    "    - If the label is normal (0), apply a broader threshold (top 50% of values).\"\"\"\n",
    "    threshold_percentile = 75 if predicted_label == 1 else 95\n",
    "    threshold_value = np.percentile(heatmap, threshold_percentile)\n",
    "    return (heatmap >= threshold_value).astype('uint8')\n",
    "\n",
    "def detect_features_in_channel(channel, mask=None):\n",
    "    features = cv2.goodFeaturesToTrack(channel, mask=mask, maxCorners=100, qualityLevel=0.01, minDistance=150)\n",
    "    return np.int0(features).reshape(-1, 2) if features is not None else np.array([])\n",
    "\n",
    "# def weighted_voting(patch_predictions, patch_confidences, image_pred, image_conf):\n",
    "#     \"\"\"Perform weighted voting based on the confidence scores.\"\"\"\n",
    "#     vote_count = {0: 0, 1: 0}  # Initialize voting counters for each class\n",
    "\n",
    "#     # Calculate the percentage of patches predicted as abnormal\n",
    "#     abnormal_patches = sum(1 for pred in patch_predictions if pred == 1)\n",
    "#     normal_patches = len(patch_predictions) - abnormal_patches\n",
    "\n",
    "#     # Adjust the weight of the full image prediction based on patch consistency\n",
    "#     if abnormal_patches > normal_patches:\n",
    "#         # Increase weight of full image prediction if majority of patches are abnormal\n",
    "#         image_weight = 5 + (abnormal_patches - normal_patches)\n",
    "#     else:\n",
    "#         # Decrease weight of full image prediction if majority of patches are normal\n",
    "#         image_weight = max(1, 5 - (normal_patches - abnormal_patches))\n",
    "\n",
    "#     if image_pred == 1:\n",
    "#         vote_count[1] += image_conf * image_weight\n",
    "#     else:\n",
    "#         vote_count[0] += (1 - image_conf) * image_weight\n",
    "\n",
    "#     # Weight adjustments based on patch predictions\n",
    "#     for pred, conf in zip(patch_predictions, patch_confidences):\n",
    "#         patch_weight = 2 if conf > 0.8 else 1  # Give higher weight to high confidence abnormal patches\n",
    "#         if pred == 1:\n",
    "#             vote_count[1] += conf * patch_weight\n",
    "#         else:\n",
    "#             vote_count[0] += (1 - conf) * patch_weight\n",
    "\n",
    "#     return 1 if vote_count[1] > vote_count[0] else 0\n",
    "\n",
    "# def weighted_voting(patch_predictions, patch_confidences, image_pred, image_conf):\n",
    "#     \"\"\"Perform weighted voting based on the confidence scores.\"\"\"\n",
    "#     vote_count = {0: 0, 1: 0}  # Initialize voting counters for each class\n",
    "\n",
    "#     # Weight adjustments based on the full image prediction\n",
    "#     image_weight = 5\n",
    "#     if image_pred == 1:\n",
    "#         vote_count[1] += image_conf * image_weight\n",
    "#     else:\n",
    "#         vote_count[0] += (1 - image_conf) * image_weight \n",
    "\n",
    "#     # Weight adjustments based on patch predictions\n",
    "#     for pred, conf in zip(patch_predictions, patch_confidences):\n",
    "#         patch_weight = 2 if conf > 0.8 else 1  # Give higher weight to high confidence abnormal patches\n",
    "#         if pred == 1:\n",
    "#             vote_count[1] += conf * patch_weight\n",
    "#         else:\n",
    "#             vote_count[0] += (1 - conf) * patch_weight\n",
    "\n",
    "#     return 1 if vote_count[1] > vote_count[0] else 0\n",
    "\n",
    "def weighted_voting(patch_predictions, patch_confidences, image_pred, image_conf):\n",
    "    \"\"\"Perform weighted voting based on the confidence scores.\"\"\"\n",
    "    vote_count = {0: 0, 1: 0}  # Initialize voting counters for each class\n",
    "\n",
    "    # Weight adjustments based on the full image prediction\n",
    "    image_weight = 5\n",
    "    if image_pred == 1:\n",
    "        vote_count[1] += image_conf * image_weight\n",
    "\n",
    "        for pred, conf in zip(patch_predictions, patch_confidences):\n",
    "            patch_weight = 2 if conf > 0.8 else 1\n",
    "            if pred == 1:\n",
    "                vote_count[1] += conf * patch_weight\n",
    "            else:\n",
    "                vote_count[0] += (1 - conf) * patch_weight\n",
    "    else:\n",
    "        vote_count[0] += (1 - image_conf) * image_weight * 5\n",
    "\n",
    "        for pred, conf in zip(patch_predictions, patch_confidences):\n",
    "            patch_weight = 3 if conf > 0.8 else 2\n",
    "            if pred == 1:\n",
    "                vote_count[1] += conf * 1.5\n",
    "            else:\n",
    "                vote_count[0] += (1 - conf) * patch_weight\n",
    "\n",
    "    return 1 if vote_count[1] > vote_count[0] else 0\n",
    "\n",
    "\n",
    "\n",
    "def save_composite_patches(image_path, extracted_patches, patch_predictions, patch_confidences, output_dir_patches):\n",
    "    base_filename = os.path.splitext(os.path.basename(image_path))[0]\n",
    "    num_patches = len(extracted_patches)\n",
    "    num_cols = 5\n",
    "    num_rows = (num_patches + num_cols - 1) // num_cols  # Ensure we have enough rows\n",
    "\n",
    "    fig, axs = plt.subplots(num_rows, num_cols, figsize=(20, 4 * num_rows))\n",
    "    axs = axs.ravel()  # Flatten the array for easy indexing\n",
    "\n",
    "    for i, (patch, pred, conf) in enumerate(zip(extracted_patches, patch_predictions, patch_confidences)):\n",
    "        axs[i].imshow(patch)\n",
    "        axs[i].axis('off')\n",
    "        axs[i].set_title(f'Pred: {pred}, Conf: {conf:.2f}')\n",
    "\n",
    "    for j in range(i + 1, len(axs)):  # Hide any unused subplots\n",
    "        axs[j].axis('off')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    patch_output_filename = os.path.join(output_dir_patches, f\"{base_filename}_patches.png\")\n",
    "    plt.savefig(patch_output_filename)\n",
    "    plt.close()\n",
    "\n",
    "def extract_and_visualize(image_path, label, model_patch, model_full, transform, correct_dir, incorrect_dir, output_dir_patches):\n",
    "    image = Image.open(image_path).convert('RGB')\n",
    "    image_np = np.array(image)\n",
    "    input_tensor = transform(image).unsqueeze(0)\n",
    "    \n",
    "    if torch.cuda.is_available():\n",
    "        input_tensor = input_tensor.cuda()\n",
    "\n",
    "    # Full image attention map\n",
    "    heatmap_full, pred_full, conf_full = get_heatmap(input_tensor, model_full, [model_full.features.norm5])\n",
    "    heatmap_resized_full = cv2.resize(heatmap_full, (image_np.shape[1], image_np.shape[0]))\n",
    "    heatmap_normalized_full = heatmap_resized_full / np.max(heatmap_resized_full)\n",
    "\n",
    "    # Apply adaptive thresholding based on predicted label\n",
    "    binary_mask_full = adaptive_thresholding(heatmap_normalized_full, pred_full)\n",
    "\n",
    "    # Overlay Image\n",
    "    overlay_img_full = cv2.addWeighted(image_np, 0.6, cv2.applyColorMap(np.uint8(255 * heatmap_normalized_full), cv2.COLORMAP_JET), 0.4, 0)\n",
    "\n",
    "    # Detect salient points\n",
    "    salient_points_all = detect_features_in_channel(cv2.cvtColor(image_np, cv2.COLOR_RGB2GRAY))  # Without mask\n",
    "    salient_points_filtered = detect_features_in_channel(cv2.cvtColor(image_np, cv2.COLOR_RGB2GRAY), binary_mask_full)  # With mask\n",
    "\n",
    "    # Image with all salient points\n",
    "    image_with_all_salient_points = image_np.copy()\n",
    "    for pt in salient_points_all:\n",
    "        cv2.circle(image_with_all_salient_points, (pt[0], pt[1]), 5, (0, 0, 255), 5)\n",
    "\n",
    "    # Image with filtered salient points\n",
    "    image_with_salient_points = image_np.copy()\n",
    "    for pt in salient_points_filtered:\n",
    "        cv2.circle(image_with_salient_points, (pt[0], pt[1]), 5, (0, 0, 255), 5)\n",
    "\n",
    "    # Image with patch classifications\n",
    "    image_with_classified_patches = image_np.copy()\n",
    "    patch_image = image_np.copy()\n",
    "    patch_predictions = []\n",
    "    patch_confidences = []\n",
    "    extracted_patches = []  # Store patches for saving\n",
    "    composite_patches = []\n",
    "    for pt in salient_points_filtered:\n",
    "        top_left_x = max(pt[0] - 137, 0)\n",
    "        top_left_y = max(pt[1] - 150, 0)\n",
    "        bottom_right_x = min(top_left_x + 275, image_with_classified_patches.shape[1])\n",
    "        bottom_right_y = min(top_left_y + 300, image_with_classified_patches.shape[0])\n",
    "\n",
    "        patch = image_with_classified_patches[top_left_y:bottom_right_y, top_left_x:bottom_right_x]\n",
    "        patch_ = patch_image[top_left_y:bottom_right_y, top_left_x:bottom_right_x]\n",
    "        extracted_patches.append(patch.copy())  # Add patch to list\n",
    "        composite_patches.append(patch_)\n",
    "        patch_tensor = torch.from_numpy(np.transpose(cv2.resize(patch, (224, 224)), (2, 0, 1)).astype('float32') / 255.0).unsqueeze(0)\n",
    "        if torch.cuda.is_available():\n",
    "            patch_tensor = patch_tensor.cuda()\n",
    "        with torch.no_grad():\n",
    "            output = model_patch(patch_tensor)\n",
    "            prob = torch.softmax(output, dim=1)\n",
    "            pred = torch.argmax(prob, dim=1)\n",
    "            conf = prob[0][pred].item()\n",
    "\n",
    "        patch_predictions.append(pred.item())\n",
    "        patch_confidences.append(conf)\n",
    "\n",
    "        color = (0, 255, 0) if pred.item() == 1 else (0, 0, 255)\n",
    "        cv2.rectangle(image_with_classified_patches, (top_left_x, top_left_y), (bottom_right_x, bottom_right_y), color, 2)\n",
    "        text = f\"{conf:.2f}\"  # Confidence score\n",
    "        cv2.putText(image_with_classified_patches, text, (top_left_x, top_left_y - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.9, (255, 0, 0), 2)\n",
    "\n",
    "    final_prediction = weighted_voting(patch_predictions, patch_confidences, pred_full, conf_full)\n",
    "\n",
    "    # Save composite patches with predictions and confidences\n",
    "    save_composite_patches(image_path, composite_patches, patch_predictions, patch_confidences, output_dir_patches)\n",
    "\n",
    "    # 3x2 Grid Visualization\n",
    "    fig, axs = plt.subplots(3, 2, figsize=(16, 24))\n",
    "    axs[0, 0].imshow(heatmap_normalized_full, cmap='jet')\n",
    "    axs[0, 0].axis('off')\n",
    "    axs[0, 0].set_title(f'Heatmap Full (DenseNet) - Pred: {pred_full}, GT: {label}')\n",
    "\n",
    "    axs[0, 1].imshow(overlay_img_full)\n",
    "    axs[0, 1].axis('off')\n",
    "    axs[0, 1].set_title('Overlay Image Full')\n",
    "\n",
    "    axs[1, 0].imshow(image_with_all_salient_points)\n",
    "    axs[1, 0].axis('off')\n",
    "    axs[1, 0].set_title('All Salient Points')\n",
    "\n",
    "    axs[1, 1].imshow(image_with_salient_points)\n",
    "    axs[1, 1].axis('off')\n",
    "    axs[1, 1].set_title('Filtered Salient Points')\n",
    "\n",
    "    axs[2, 0].imshow(image_with_classified_patches)\n",
    "    axs[2, 0].axis('off')\n",
    "    axs[2, 0].set_title('Patch Classifications')\n",
    "\n",
    "    # Leave the last grid empty if not needed\n",
    "    axs[2, 1].axis('off')\n",
    "\n",
    "    if final_prediction == label:\n",
    "        output_filename = os.path.join(correct_dir, f\"{os.path.splitext(os.path.basename(image_path))[0]}_composite.png\")\n",
    "    else:\n",
    "        output_filename = os.path.join(incorrect_dir, f\"{os.path.splitext(os.path.basename(image_path))[0]}_composite.png\")\n",
    "\n",
    "    plt.savefig(output_filename)\n",
    "    plt.close()\n",
    "\n",
    "    return final_prediction, label\n",
    "\n",
    "# Directory and processing setup\n",
    "root_dir = 'Data/Testing/Images'\n",
    "output_dir_correct = 'Processed_Images_pred_correct_3'\n",
    "output_dir_incorrect = 'Processed_Images_pred_incorrect_3'\n",
    "output_dir_patches = 'Processed_Patches_3'\n",
    "os.makedirs(output_dir_correct, exist_ok=True)\n",
    "os.makedirs(output_dir_incorrect, exist_ok=True)\n",
    "os.makedirs(output_dir_patches, exist_ok=True)\n",
    "\n",
    "all_predictions = []\n",
    "all_labels = []\n",
    "\n",
    "for subfolder in ['abnormal_testing_images', 'normal_testing_images']:\n",
    "    folder_path = os.path.join(root_dir, subfolder)\n",
    "    label = 0 if subfolder == 'normal_testing_images' else 1\n",
    "    for image_file in os.listdir(folder_path):\n",
    "        if image_file.lower().endswith(('.png', '.jpg', '.jpeg')):\n",
    "            image_path = os.path.join(folder_path, image_file)\n",
    "            final_prediction, true_label = extract_and_visualize(image_path, label, model_patch, model_full, transform, output_dir_correct, output_dir_incorrect, output_dir_patches)\n",
    "            all_predictions.append(final_prediction)\n",
    "            all_labels.append(true_label)\n",
    "\n",
    "# Calculate and print accuracy, precision, and reca\n",
    "accuracy = accuracy_score(all_labels, all_predictions)\n",
    "precision = precision_score(all_labels, all_predictions)\n",
    "recall = recall_score(all_labels, all_predictions)\n",
    "\n",
    "print(f\"Completed processing. Check the output directories: {output_dir_correct}, {output_dir_incorrect}, and {output_dir_patches}\")\n",
    "print(f\"Accuracy: {accuracy:.4f}\")\n",
    "print(f\"Precision: {precision:.4f}\")\n",
    "print(f\"Recall: {recall:.4f}\")\n",
    "\n",
    "\n",
    "# This one seems to classify patches better. Just work on the weighted voting now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed processing. Check the output directories: Processed_Images_pred_correct_4, Processed_Images_pred_incorrect_4, and Processed_Patches_4\n",
      "Accuracy: 0.8130\n",
      "Precision: 0.7528\n",
      "Recall: 0.9853\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "from pytorch_grad_cam import GradCAMPlusPlus\n",
    "from pytorch_grad_cam.utils.model_targets import ClassifierOutputTarget\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score\n",
    "import torchvision.models as models\n",
    "\n",
    "# Custom dataset class\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, images, labels, transform=None):\n",
    "        self.images = images\n",
    "        self.labels = labels\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image = self.images[idx]\n",
    "        label = self.labels[idx]\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        return image, label\n",
    "\n",
    "# Define transformations for testing\n",
    "test_transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])\n",
    "\n",
    "# Load your pre-trained PyTorch models for patches and full images\n",
    "model_patch = torch.load('Models/Patch_Model_All_Data_DenseNet', map_location=torch.device('cpu'))\n",
    "model_patch.eval()\n",
    "model_full = torch.load('Models/denseNet_redo_full_images', map_location=torch.device('cpu'))\n",
    "model_full.eval()\n",
    "\n",
    "# Transformation pipeline for image preprocessing\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "def get_heatmap(input_tensor, model, target_layers):\n",
    "    cam = GradCAMPlusPlus(model=model, target_layers=target_layers)\n",
    "    pred = model(input_tensor)\n",
    "    _, predicted_class = pred.max(1)\n",
    "    targets = [ClassifierOutputTarget(predicted_class.item())]\n",
    "    grayscale_cam = cam(input_tensor=input_tensor, targets=targets)[0, :]\n",
    "    return grayscale_cam, predicted_class.item(), torch.softmax(pred, dim=1)[0, predicted_class].item()\n",
    "\n",
    "def adaptive_thresholding(heatmap, predicted_label):\n",
    "    \"\"\"Determine the threshold based on the predicted label.\n",
    "    - If the label is abnormal (1), apply a stricter threshold (top 25% of values).\n",
    "    - If the label is normal (0), apply a broader threshold (top 50% of values).\"\"\"\n",
    "    threshold_percentile = 75 if predicted_label == 1 else 95\n",
    "    threshold_value = np.percentile(heatmap, threshold_percentile)\n",
    "    return (heatmap >= threshold_value).astype('uint8')\n",
    "\n",
    "def detect_features_in_channel(channel, mask=None):\n",
    "    features = cv2.goodFeaturesToTrack(channel, mask=mask, maxCorners=100, qualityLevel=0.01, minDistance=150)\n",
    "    return np.int0(features).reshape(-1, 2) if features is not None else np.array([])\n",
    "\n",
    "# def weighted_voting(patch_predictions, patch_confidences, image_pred, image_conf):\n",
    "#     \"\"\"Perform weighted voting based on the confidence scores.\"\"\"\n",
    "#     vote_count = {0: 0, 1: 0}  # Initialize voting counters for each class\n",
    "\n",
    "#     # Calculate the percentage of patches predicted as abnormal\n",
    "#     abnormal_patches = sum(1 for pred in patch_predictions if pred == 1)\n",
    "#     normal_patches = len(patch_predictions) - abnormal_patches\n",
    "\n",
    "#     # Adjust the weight of the full image prediction based on patch consistency\n",
    "#     if abnormal_patches > normal_patches:\n",
    "#         # Increase weight of full image prediction if majority of patches are abnormal\n",
    "#         image_weight = 5 + (abnormal_patches - normal_patches)\n",
    "#     else:\n",
    "#         # Decrease weight of full image prediction if majority of patches are normal\n",
    "#         image_weight = max(1, 5 - (normal_patches - abnormal_patches))\n",
    "\n",
    "#     if image_pred == 1:\n",
    "#         vote_count[1] += image_conf * image_weight\n",
    "#     else:\n",
    "#         vote_count[0] += (1 - image_conf) * image_weight\n",
    "\n",
    "#     # Weight adjustments based on patch predictions\n",
    "#     for pred, conf in zip(patch_predictions, patch_confidences):\n",
    "#         patch_weight = 2 if conf > 0.8 else 1  # Give higher weight to high confidence abnormal patches\n",
    "#         if pred == 1:\n",
    "#             vote_count[1] += conf * patch_weight\n",
    "#         else:\n",
    "#             vote_count[0] += (1 - conf) * patch_weight\n",
    "\n",
    "#     return 1 if vote_count[1] > vote_count[0] else 0\n",
    "\n",
    "# def weighted_voting(patch_predictions, patch_confidences, image_pred, image_conf):\n",
    "#     \"\"\"Perform weighted voting based on the confidence scores.\"\"\"\n",
    "#     vote_count = {0: 0, 1: 0}  # Initialize voting counters for each class\n",
    "\n",
    "#     # Weight adjustments based on the full image prediction\n",
    "#     image_weight = 5\n",
    "#     if image_pred == 1:\n",
    "#         vote_count[1] += image_conf * image_weight\n",
    "#     else:\n",
    "#         vote_count[0] += (1 - image_conf) * image_weight \n",
    "\n",
    "#     # Weight adjustments based on patch predictions\n",
    "#     for pred, conf in zip(patch_predictions, patch_confidences):\n",
    "#         patch_weight = 2 if conf > 0.8 else 1  # Give higher weight to high confidence abnormal patches\n",
    "#         if pred == 1:\n",
    "#             vote_count[1] += conf * patch_weight\n",
    "#         else:\n",
    "#             vote_count[0] += (1 - conf) * patch_weight\n",
    "\n",
    "#     return 1 if vote_count[1] > vote_count[0] else 0\n",
    "\n",
    "def weighted_voting(patch_predictions, patch_confidences, image_pred, image_conf):\n",
    "    \"\"\"Perform weighted voting based on the confidence scores.\"\"\"\n",
    "    vote_count = {0: 0, 1: 0}  # Initialize voting counters for each class\n",
    "\n",
    "    # Weight adjustments based on the full image prediction\n",
    "    image_weight = 2\n",
    "    if image_pred == 1:\n",
    "        vote_count[1] += image_conf * image_weight\n",
    "\n",
    "        for pred, conf in zip(patch_predictions, patch_confidences):\n",
    "            patch_weight = 2 if conf > 0.8 else 1\n",
    "            if pred == 1:\n",
    "                vote_count[1] += conf * patch_weight\n",
    "            else:\n",
    "                vote_count[0] += (1 - conf) * patch_weight\n",
    "    else:\n",
    "        vote_count[0] += (1 - image_conf) * image_weight\n",
    "\n",
    "        for pred, conf in zip(patch_predictions, patch_confidences):\n",
    "            patch_weight = 3 if conf > 0.8 else 2\n",
    "            if pred == 1:\n",
    "                vote_count[1] += conf * 1.5\n",
    "            else:\n",
    "                vote_count[0] += (1 - conf) * patch_weight\n",
    "\n",
    "    return 1 if vote_count[1] > vote_count[0] else 0\n",
    "\n",
    "\n",
    "\n",
    "def save_composite_patches(image_path, extracted_patches, patch_predictions, patch_confidences, output_dir_patches):\n",
    "    base_filename = os.path.splitext(os.path.basename(image_path))[0]\n",
    "    num_patches = len(extracted_patches)\n",
    "    num_cols = 5\n",
    "    num_rows = (num_patches + num_cols - 1) // num_cols  # Ensure we have enough rows\n",
    "\n",
    "    fig, axs = plt.subplots(num_rows, num_cols, figsize=(20, 4 * num_rows))\n",
    "    axs = axs.ravel()  # Flatten the array for easy indexing\n",
    "\n",
    "    for i, (patch, pred, conf) in enumerate(zip(extracted_patches, patch_predictions, patch_confidences)):\n",
    "        axs[i].imshow(patch)\n",
    "        axs[i].axis('off')\n",
    "        axs[i].set_title(f'Pred: {pred}, Conf: {conf:.2f}')\n",
    "\n",
    "    for j in range(i + 1, len(axs)):  # Hide any unused subplots\n",
    "        axs[j].axis('off')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    patch_output_filename = os.path.join(output_dir_patches, f\"{base_filename}_patches.png\")\n",
    "    plt.savefig(patch_output_filename)\n",
    "    plt.close()\n",
    "\n",
    "def extract_and_visualize(image_path, label, model_patch, model_full, transform, correct_dir, incorrect_dir, output_dir_patches):\n",
    "    image = Image.open(image_path).convert('RGB')\n",
    "    image_np = np.array(image)\n",
    "    input_tensor = transform(image).unsqueeze(0)\n",
    "    \n",
    "    if torch.cuda.is_available():\n",
    "        input_tensor = input_tensor.cuda()\n",
    "\n",
    "    # Full image attention map\n",
    "    heatmap_full, pred_full, conf_full = get_heatmap(input_tensor, model_full, [model_full.features.norm5])\n",
    "    heatmap_resized_full = cv2.resize(heatmap_full, (image_np.shape[1], image_np.shape[0]))\n",
    "    heatmap_normalized_full = heatmap_resized_full / np.max(heatmap_resized_full)\n",
    "\n",
    "    # Apply adaptive thresholding based on predicted label\n",
    "    binary_mask_full = adaptive_thresholding(heatmap_normalized_full, pred_full)\n",
    "\n",
    "    # Overlay Image\n",
    "    overlay_img_full = cv2.addWeighted(image_np, 0.6, cv2.applyColorMap(np.uint8(255 * heatmap_normalized_full), cv2.COLORMAP_JET), 0.4, 0)\n",
    "\n",
    "    # Detect salient points\n",
    "    salient_points_all = detect_features_in_channel(cv2.cvtColor(image_np, cv2.COLOR_RGB2GRAY))  # Without mask\n",
    "    salient_points_filtered = detect_features_in_channel(cv2.cvtColor(image_np, cv2.COLOR_RGB2GRAY), binary_mask_full)  # With mask\n",
    "\n",
    "    # Image with all salient points\n",
    "    image_with_all_salient_points = image_np.copy()\n",
    "    for pt in salient_points_all:\n",
    "        cv2.circle(image_with_all_salient_points, (pt[0], pt[1]), 5, (0, 0, 255), 5)\n",
    "\n",
    "    # Image with filtered salient points\n",
    "    image_with_salient_points = image_np.copy()\n",
    "    for pt in salient_points_filtered:\n",
    "        cv2.circle(image_with_salient_points, (pt[0], pt[1]), 5, (0, 0, 255), 5)\n",
    "\n",
    "    # Image with patch classifications\n",
    "    image_with_classified_patches = image_np.copy()\n",
    "    patch_image = image_np.copy()\n",
    "    patch_predictions = []\n",
    "    patch_confidences = []\n",
    "    extracted_patches = []  # Store patches for saving\n",
    "    composite_patches = []\n",
    "    for pt in salient_points_filtered:\n",
    "        top_left_x = max(pt[0] - 137, 0)\n",
    "        top_left_y = max(pt[1] - 150, 0)\n",
    "        bottom_right_x = min(top_left_x + 275, image_with_classified_patches.shape[1])\n",
    "        bottom_right_y = min(top_left_y + 300, image_with_classified_patches.shape[0])\n",
    "\n",
    "        patch = image_with_classified_patches[top_left_y:bottom_right_y, top_left_x:bottom_right_x]\n",
    "        patch_ = patch_image[top_left_y:bottom_right_y, top_left_x:bottom_right_x]\n",
    "        extracted_patches.append(patch.copy())  # Add patch to list\n",
    "        composite_patches.append(patch_)\n",
    "        patch_tensor = torch.from_numpy(np.transpose(cv2.resize(patch, (224, 224)), (2, 0, 1)).astype('float32') / 255.0).unsqueeze(0)\n",
    "        if torch.cuda.is_available():\n",
    "            patch_tensor = patch_tensor.cuda()\n",
    "        with torch.no_grad():\n",
    "            output = model_patch(patch_tensor)\n",
    "            prob = torch.softmax(output, dim=1)\n",
    "            pred = torch.argmax(prob, dim=1)\n",
    "            conf = prob[0][pred].item()\n",
    "\n",
    "        patch_predictions.append(pred.item())\n",
    "        patch_confidences.append(conf)\n",
    "\n",
    "        color = (0, 255, 0) if pred.item() == 1 else (0, 0, 255)\n",
    "        cv2.rectangle(image_with_classified_patches, (top_left_x, top_left_y), (bottom_right_x, bottom_right_y), color, 2)\n",
    "        text = f\"{conf:.2f}\"  # Confidence score\n",
    "        cv2.putText(image_with_classified_patches, text, (top_left_x, top_left_y - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.9, (255, 0, 0), 2)\n",
    "\n",
    "    final_prediction = weighted_voting(patch_predictions, patch_confidences, pred_full, conf_full)\n",
    "\n",
    "    # Save composite patches with predictions and confidences\n",
    "    save_composite_patches(image_path, composite_patches, patch_predictions, patch_confidences, output_dir_patches)\n",
    "\n",
    "    # 3x2 Grid Visualization\n",
    "    fig, axs = plt.subplots(3, 2, figsize=(16, 24))\n",
    "    axs[0, 0].imshow(heatmap_normalized_full, cmap='jet')\n",
    "    axs[0, 0].axis('off')\n",
    "    axs[0, 0].set_title(f'Heatmap Full (DenseNet) - Pred: {pred_full}, GT: {label}, Final_Pred: {final_prediction}')\n",
    "\n",
    "    axs[0, 1].imshow(overlay_img_full)\n",
    "    axs[0, 1].axis('off')\n",
    "    axs[0, 1].set_title('Overlay Image Full')\n",
    "\n",
    "    axs[1, 0].imshow(image_with_all_salient_points)\n",
    "    axs[1, 0].axis('off')\n",
    "    axs[1, 0].set_title('All Salient Points')\n",
    "\n",
    "    axs[1, 1].imshow(image_with_salient_points)\n",
    "    axs[1, 1].axis('off')\n",
    "    axs[1, 1].set_title('Filtered Salient Points')\n",
    "\n",
    "    axs[2, 0].imshow(image_with_classified_patches)\n",
    "    axs[2, 0].axis('off')\n",
    "    axs[2, 0].set_title('Patch Classifications')\n",
    "\n",
    "    # Leave the last grid empty if not needed\n",
    "    axs[2, 1].axis('off')\n",
    "\n",
    "    if final_prediction == label:\n",
    "        output_filename = os.path.join(correct_dir, f\"{os.path.splitext(os.path.basename(image_path))[0]}_composite.png\")\n",
    "    else:\n",
    "        output_filename = os.path.join(incorrect_dir, f\"{os.path.splitext(os.path.basename(image_path))[0]}_composite.png\")\n",
    "\n",
    "    plt.savefig(output_filename)\n",
    "    plt.close()\n",
    "\n",
    "    return final_prediction, label\n",
    "\n",
    "# Directory and processing setup\n",
    "root_dir = 'Data/Testing/Images'\n",
    "output_dir_correct = 'Processed_Images_pred_correct_4'\n",
    "output_dir_incorrect = 'Processed_Images_pred_incorrect_4'\n",
    "output_dir_patches = 'Processed_Patches_4'\n",
    "os.makedirs(output_dir_correct, exist_ok=True)\n",
    "os.makedirs(output_dir_incorrect, exist_ok=True)\n",
    "os.makedirs(output_dir_patches, exist_ok=True)\n",
    "\n",
    "all_predictions = []\n",
    "all_labels = []\n",
    "\n",
    "for subfolder in ['abnormal_testing_images', 'normal_testing_images']:\n",
    "    folder_path = os.path.join(root_dir, subfolder)\n",
    "    label = 0 if subfolder == 'normal_testing_images' else 1\n",
    "    for image_file in os.listdir(folder_path):\n",
    "        if image_file.lower().endswith(('.png', '.jpg', '.jpeg')):\n",
    "            image_path = os.path.join(folder_path, image_file)\n",
    "            final_prediction, true_label = extract_and_visualize(image_path, label, model_patch, model_full, transform, output_dir_correct, output_dir_incorrect, output_dir_patches)\n",
    "            all_predictions.append(final_prediction)\n",
    "            all_labels.append(true_label)\n",
    "\n",
    "# Calculate and print accuracy, precision, and reca\n",
    "accuracy = accuracy_score(all_labels, all_predictions)\n",
    "precision = precision_score(all_labels, all_predictions)\n",
    "recall = recall_score(all_labels, all_predictions)\n",
    "\n",
    "print(f\"Completed processing. Check the output directories: {output_dir_correct}, {output_dir_incorrect}, and {output_dir_patches}\")\n",
    "print(f\"Accuracy: {accuracy:.4f}\")\n",
    "print(f\"Precision: {precision:.4f}\")\n",
    "print(f\"Recall: {recall:.4f}\")\n",
    "\n",
    "# This one seems to classify patches better. Just work on the weighted voting now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed processing. Check the output directories: Processed_Images_pred_correct_5, Processed_Images_pred_incorrect_5, and Processed_Patches_5\n",
      "Accuracy: 0.8089\n",
      "Precision: 0.7514\n",
      "Recall: 0.9779\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "from pytorch_grad_cam import GradCAMPlusPlus\n",
    "from pytorch_grad_cam.utils.model_targets import ClassifierOutputTarget\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score\n",
    "import torchvision.models as models\n",
    "\n",
    "# Custom dataset class\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, images, labels, transform=None):\n",
    "        self.images = images\n",
    "        self.labels = labels\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image = self.images[idx]\n",
    "        label = self.labels[idx]\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        return image, label\n",
    "\n",
    "# Define transformations for testing\n",
    "test_transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])\n",
    "\n",
    "# Load your pre-trained PyTorch models for patches and full images\n",
    "model_patch = torch.load('Models/Patch_Model_All_Data_DenseNet_2', map_location=torch.device('cpu'))\n",
    "model_patch.eval()\n",
    "model_full = torch.load('Models/denseNet_redo_full_images', map_location=torch.device('cpu'))\n",
    "model_full.eval()\n",
    "\n",
    "# Transformation pipeline for image preprocessing\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "def get_heatmap(input_tensor, model, target_layers):\n",
    "    cam = GradCAMPlusPlus(model=model, target_layers=target_layers)\n",
    "    pred = model(input_tensor)\n",
    "    _, predicted_class = pred.max(1)\n",
    "    targets = [ClassifierOutputTarget(predicted_class.item())]\n",
    "    grayscale_cam = cam(input_tensor=input_tensor, targets=targets)[0, :]\n",
    "    return grayscale_cam, predicted_class.item(), torch.softmax(pred, dim=1)[0, predicted_class].item()\n",
    "\n",
    "def adaptive_thresholding(heatmap, predicted_label):\n",
    "    \"\"\"Determine the threshold based on the predicted label.\n",
    "    - If the label is abnormal (1), apply a stricter threshold (top 25% of values).\n",
    "    - If the label is normal (0), apply a broader threshold (top 50% of values).\"\"\"\n",
    "    threshold_percentile = 75 if predicted_label == 1 else 95\n",
    "    threshold_value = np.percentile(heatmap, threshold_percentile)\n",
    "    return (heatmap >= threshold_value).astype('uint8')\n",
    "\n",
    "def detect_features_in_channel(channel, mask=None):\n",
    "    features = cv2.goodFeaturesToTrack(channel, mask=mask, maxCorners=100, qualityLevel=0.01, minDistance=150)\n",
    "    return np.int0(features).reshape(-1, 2) if features is not None else np.array([])\n",
    "\n",
    "# def weighted_voting(patch_predictions, patch_confidences, image_pred, image_conf):\n",
    "#     \"\"\"Perform weighted voting based on the confidence scores.\"\"\"\n",
    "#     vote_count = {0: 0, 1: 0}  # Initialize voting counters for each class\n",
    "\n",
    "#     # Calculate the percentage of patches predicted as abnormal\n",
    "#     abnormal_patches = sum(1 for pred in patch_predictions if pred == 1)\n",
    "#     normal_patches = len(patch_predictions) - abnormal_patches\n",
    "\n",
    "#     # Adjust the weight of the full image prediction based on patch consistency\n",
    "#     if abnormal_patches > normal_patches:\n",
    "#         # Increase weight of full image prediction if majority of patches are abnormal\n",
    "#         image_weight = 5 + (abnormal_patches - normal_patches)\n",
    "#     else:\n",
    "#         # Decrease weight of full image prediction if majority of patches are normal\n",
    "#         image_weight = max(1, 5 - (normal_patches - abnormal_patches))\n",
    "\n",
    "#     if image_pred == 1:\n",
    "#         vote_count[1] += image_conf * image_weight\n",
    "#     else:\n",
    "#         vote_count[0] += (1 - image_conf) * image_weight\n",
    "\n",
    "#     # Weight adjustments based on patch predictions\n",
    "#     for pred, conf in zip(patch_predictions, patch_confidences):\n",
    "#         patch_weight = 2 if conf > 0.8 else 1  # Give higher weight to high confidence abnormal patches\n",
    "#         if pred == 1:\n",
    "#             vote_count[1] += conf * patch_weight\n",
    "#         else:\n",
    "#             vote_count[0] += (1 - conf) * patch_weight\n",
    "\n",
    "#     return 1 if vote_count[1] > vote_count[0] else 0\n",
    "\n",
    "# def weighted_voting(patch_predictions, patch_confidences, image_pred, image_conf):\n",
    "#     \"\"\"Perform weighted voting based on the confidence scores.\"\"\"\n",
    "#     vote_count = {0: 0, 1: 0}  # Initialize voting counters for each class\n",
    "\n",
    "#     # Weight adjustments based on the full image prediction\n",
    "#     image_weight = 5\n",
    "#     if image_pred == 1:\n",
    "#         vote_count[1] += image_conf * image_weight\n",
    "#     else:\n",
    "#         vote_count[0] += (1 - image_conf) * image_weight \n",
    "\n",
    "#     # Weight adjustments based on patch predictions\n",
    "#     for pred, conf in zip(patch_predictions, patch_confidences):\n",
    "#         patch_weight = 2 if conf > 0.8 else 1  # Give higher weight to high confidence abnormal patches\n",
    "#         if pred == 1:\n",
    "#             vote_count[1] += conf * patch_weight\n",
    "#         else:\n",
    "#             vote_count[0] += (1 - conf) * patch_weight\n",
    "\n",
    "#     return 1 if vote_count[1] > vote_count[0] else 0\n",
    "\n",
    "def weighted_voting(patch_predictions, patch_confidences, image_pred, image_conf):\n",
    "    \"\"\"Perform weighted voting based on the confidence scores.\"\"\"\n",
    "    vote_count = {0: 0, 1: 0}  # Initialize voting counters for each class\n",
    "\n",
    "    # Weight adjustments based on the full image prediction\n",
    "    image_weight = 2\n",
    "    if image_pred == 1:\n",
    "        vote_count[1] += image_conf * image_weight\n",
    "\n",
    "        for pred, conf in zip(patch_predictions, patch_confidences):\n",
    "            patch_weight = 2 if conf > 0.8 else 1\n",
    "            if pred == 1:\n",
    "                vote_count[1] += conf * patch_weight\n",
    "            else:\n",
    "                vote_count[0] += (1 - conf) * patch_weight\n",
    "    else:\n",
    "        vote_count[0] += (1 - image_conf) * image_weight\n",
    "\n",
    "        for pred, conf in zip(patch_predictions, patch_confidences):\n",
    "            patch_weight = 3 if conf > 0.8 else 2\n",
    "            if pred == 1:\n",
    "                vote_count[1] += conf * 1.5\n",
    "            else:\n",
    "                vote_count[0] += (1 - conf) * patch_weight\n",
    "\n",
    "    return 1 if vote_count[1] > vote_count[0] else 0\n",
    "\n",
    "\n",
    "\n",
    "def save_composite_patches(image_path, extracted_patches, patch_predictions, patch_confidences, output_dir_patches):\n",
    "    base_filename = os.path.splitext(os.path.basename(image_path))[0]\n",
    "    num_patches = len(extracted_patches)\n",
    "    num_cols = 5\n",
    "    num_rows = (num_patches + num_cols - 1) // num_cols  # Ensure we have enough rows\n",
    "\n",
    "    fig, axs = plt.subplots(num_rows, num_cols, figsize=(20, 4 * num_rows))\n",
    "    axs = axs.ravel()  # Flatten the array for easy indexing\n",
    "\n",
    "    for i, (patch, pred, conf) in enumerate(zip(extracted_patches, patch_predictions, patch_confidences)):\n",
    "        axs[i].imshow(patch)\n",
    "        axs[i].axis('off')\n",
    "        axs[i].set_title(f'Pred: {pred}, Conf: {conf:.2f}')\n",
    "\n",
    "    for j in range(i + 1, len(axs)):  # Hide any unused subplots\n",
    "        axs[j].axis('off')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    patch_output_filename = os.path.join(output_dir_patches, f\"{base_filename}_patches.png\")\n",
    "    plt.savefig(patch_output_filename)\n",
    "    plt.close()\n",
    "\n",
    "def extract_and_visualize(image_path, label, model_patch, model_full, transform, correct_dir, incorrect_dir, output_dir_patches):\n",
    "    image = Image.open(image_path).convert('RGB')\n",
    "    image_np = np.array(image)\n",
    "    input_tensor = transform(image).unsqueeze(0)\n",
    "    \n",
    "    if torch.cuda.is_available():\n",
    "        input_tensor = input_tensor.cuda()\n",
    "\n",
    "    # Full image attention map\n",
    "    heatmap_full, pred_full, conf_full = get_heatmap(input_tensor, model_full, [model_full.features.norm5])\n",
    "    heatmap_resized_full = cv2.resize(heatmap_full, (image_np.shape[1], image_np.shape[0]))\n",
    "    heatmap_normalized_full = heatmap_resized_full / np.max(heatmap_resized_full)\n",
    "\n",
    "    # Apply adaptive thresholding based on predicted label\n",
    "    binary_mask_full = adaptive_thresholding(heatmap_normalized_full, pred_full)\n",
    "\n",
    "    # Overlay Image\n",
    "    overlay_img_full = cv2.addWeighted(image_np, 0.6, cv2.applyColorMap(np.uint8(255 * heatmap_normalized_full), cv2.COLORMAP_JET), 0.4, 0)\n",
    "\n",
    "    # Detect salient points\n",
    "    salient_points_all = detect_features_in_channel(cv2.cvtColor(image_np, cv2.COLOR_RGB2GRAY))  # Without mask\n",
    "    salient_points_filtered = detect_features_in_channel(cv2.cvtColor(image_np, cv2.COLOR_RGB2GRAY), binary_mask_full)  # With mask\n",
    "\n",
    "    # Image with all salient points\n",
    "    image_with_all_salient_points = image_np.copy()\n",
    "    for pt in salient_points_all:\n",
    "        cv2.circle(image_with_all_salient_points, (pt[0], pt[1]), 5, (0, 0, 255), 5)\n",
    "\n",
    "    # Image with filtered salient points\n",
    "    image_with_salient_points = image_np.copy()\n",
    "    for pt in salient_points_filtered:\n",
    "        cv2.circle(image_with_salient_points, (pt[0], pt[1]), 5, (0, 0, 255), 5)\n",
    "\n",
    "    # Image with patch classifications\n",
    "    image_with_classified_patches = image_np.copy()\n",
    "    patch_image = image_np.copy()\n",
    "    patch_predictions = []\n",
    "    patch_confidences = []\n",
    "    extracted_patches = []  # Store patches for saving\n",
    "    composite_patches = []\n",
    "    for pt in salient_points_filtered:\n",
    "        top_left_x = max(pt[0] - 137, 0)\n",
    "        top_left_y = max(pt[1] - 150, 0)\n",
    "        bottom_right_x = min(top_left_x + 275, image_with_classified_patches.shape[1])\n",
    "        bottom_right_y = min(top_left_y + 300, image_with_classified_patches.shape[0])\n",
    "\n",
    "        patch = image_with_classified_patches[top_left_y:bottom_right_y, top_left_x:bottom_right_x]\n",
    "        patch_ = patch_image[top_left_y:bottom_right_y, top_left_x:bottom_right_x]\n",
    "        extracted_patches.append(patch.copy())  # Add patch to list\n",
    "        composite_patches.append(patch_)\n",
    "        patch_tensor = torch.from_numpy(np.transpose(cv2.resize(patch, (224, 224)), (2, 0, 1)).astype('float32') / 255.0).unsqueeze(0)\n",
    "        if torch.cuda.is_available():\n",
    "            patch_tensor = patch_tensor.cuda()\n",
    "        with torch.no_grad():\n",
    "            output = model_patch(patch_tensor)\n",
    "            prob = torch.softmax(output, dim=1)\n",
    "            pred = torch.argmax(prob, dim=1)\n",
    "            conf = prob[0][pred].item()\n",
    "\n",
    "        patch_predictions.append(pred.item())\n",
    "        patch_confidences.append(conf)\n",
    "\n",
    "        color = (0, 255, 0) if pred.item() == 1 else (0, 0, 255)\n",
    "        cv2.rectangle(image_with_classified_patches, (top_left_x, top_left_y), (bottom_right_x, bottom_right_y), color, 2)\n",
    "        text = f\"{conf:.2f}\"  # Confidence score\n",
    "        cv2.putText(image_with_classified_patches, text, (top_left_x, top_left_y - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.9, (255, 0, 0), 2)\n",
    "\n",
    "    final_prediction = weighted_voting(patch_predictions, patch_confidences, pred_full, conf_full)\n",
    "\n",
    "    # Save composite patches with predictions and confidences\n",
    "    save_composite_patches(image_path, composite_patches, patch_predictions, patch_confidences, output_dir_patches)\n",
    "\n",
    "    # 3x2 Grid Visualization\n",
    "    fig, axs = plt.subplots(3, 2, figsize=(16, 24))\n",
    "    axs[0, 0].imshow(heatmap_normalized_full, cmap='jet')\n",
    "    axs[0, 0].axis('off')\n",
    "    axs[0, 0].set_title(f'Heatmap Full (DenseNet) - Pred: {pred_full}, GT: {label}, Final_Pred: {final_prediction}')\n",
    "\n",
    "    axs[0, 1].imshow(overlay_img_full)\n",
    "    axs[0, 1].axis('off')\n",
    "    axs[0, 1].set_title('Overlay Image Full')\n",
    "\n",
    "    axs[1, 0].imshow(image_with_all_salient_points)\n",
    "    axs[1, 0].axis('off')\n",
    "    axs[1, 0].set_title('All Salient Points')\n",
    "\n",
    "    axs[1, 1].imshow(image_with_salient_points)\n",
    "    axs[1, 1].axis('off')\n",
    "    axs[1, 1].set_title('Filtered Salient Points')\n",
    "\n",
    "    axs[2, 0].imshow(image_with_classified_patches)\n",
    "    axs[2, 0].axis('off')\n",
    "    axs[2, 0].set_title('Patch Classifications')\n",
    "\n",
    "    # Leave the last grid empty if not needed\n",
    "    axs[2, 1].axis('off')\n",
    "\n",
    "    if final_prediction == label:\n",
    "        output_filename = os.path.join(correct_dir, f\"{os.path.splitext(os.path.basename(image_path))[0]}_composite.png\")\n",
    "    else:\n",
    "        output_filename = os.path.join(incorrect_dir, f\"{os.path.splitext(os.path.basename(image_path))[0]}_composite.png\")\n",
    "\n",
    "    plt.savefig(output_filename)\n",
    "    plt.close()\n",
    "\n",
    "    return final_prediction, label\n",
    "\n",
    "# Directory and processing setup\n",
    "root_dir = 'Data/Testing/Images'\n",
    "output_dir_correct = 'Processed_Images_pred_correct_5'\n",
    "output_dir_incorrect = 'Processed_Images_pred_incorrect_5'\n",
    "output_dir_patches = 'Processed_Patches_5'\n",
    "os.makedirs(output_dir_correct, exist_ok=True)\n",
    "os.makedirs(output_dir_incorrect, exist_ok=True)\n",
    "os.makedirs(output_dir_patches, exist_ok=True)\n",
    "\n",
    "all_predictions = []\n",
    "all_labels = []\n",
    "\n",
    "for subfolder in ['abnormal_testing_images', 'normal_testing_images']:\n",
    "    folder_path = os.path.join(root_dir, subfolder)\n",
    "    label = 0 if subfolder == 'normal_testing_images' else 1\n",
    "    for image_file in os.listdir(folder_path):\n",
    "        if image_file.lower().endswith(('.png', '.jpg', '.jpeg')):\n",
    "            image_path = os.path.join(folder_path, image_file)\n",
    "            final_prediction, true_label = extract_and_visualize(image_path, label, model_patch, model_full, transform, output_dir_correct, output_dir_incorrect, output_dir_patches)\n",
    "            all_predictions.append(final_prediction)\n",
    "            all_labels.append(true_label)\n",
    "\n",
    "# Calculate and print accuracy, precision, and reca\n",
    "accuracy = accuracy_score(all_labels, all_predictions)\n",
    "precision = precision_score(all_labels, all_predictions)\n",
    "recall = recall_score(all_labels, all_predictions)\n",
    "\n",
    "print(f\"Completed processing. Check the output directories: {output_dir_correct}, {output_dir_incorrect}, and {output_dir_patches}\")\n",
    "print(f\"Accuracy: {accuracy:.4f}\")\n",
    "print(f\"Precision: {precision:.4f}\")\n",
    "print(f\"Recall: {recall:.4f}\")\n",
    "\n",
    "# This one seems to classify patches better. Just work on the weighted voting now."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
